{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import build_opener\n",
    "from urllib.request import install_opener\n",
    "import os\n",
    "import pathlib\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers, metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "# for physical_device in physical_devices: \n",
    "#     tf.config.experimental.set_memory_growth(physical_device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count how many images in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name_list = ['001_Bulbasaur', '002_Ivysaur', '003_Venusaur', '004_Charmander', '005_Charmeleon',\n",
    " '006_Charizard', '007_Squirtle', '008_Wartortle', '009_Blastoise', '010_Caterpie', '011_Metapod',\n",
    " '012_Butterfree', '013_Weedle', '014_Kakuna', '015_Beedrill', '016_Pidgey', '017_Pidgeotto', '018_Pidgeot',\n",
    " '019_Rattata', '020_Raticate', '021_Spearow', '022_Fearow', '023_Ekans', '024_Arbok', '025_Pikachu', '026_Raichu',\n",
    " '027_Sandshrew', '028_Sandslash', '029_Nidoran♀', '030_Nidorina', '031_Nidoqueen', '032_Nidoran♂', '033_Nidorino',\n",
    " '034_Nidoking', '035_Clefairy', '036_Clefable', '037_Vulpix', '038_Ninetales', '039_Jigglypuff', '040_Wigglytuff',\n",
    " '041_Zubat', '042_Golbat', '043_Oddish', '044_Gloom', '045_Vileplume', '046_Paras', '047_Parasect', '048_Venonat',\n",
    " '049_Venomoth', '050_Diglett', '051_Dugtrio', '052_Meowth', '053_Persian', '054_Psyduck', '055_Golduck', '056_Mankey',\n",
    " '057_Primeape', '058_Growlithe', '059_Arcanine', '060_Poliwag', '061_Poliwhirl', '062_Poliwrath', '063_Abra',\n",
    " '064_Kadabra', '065_Alakazam', '066_Machop', '067_Machoke', '068_Machamp', '069_Bellsprout', '070_Weepinbell',\n",
    " '071_Victreebel', '072_Tentacool', '073_Tentacruel', '074_Geodude', '075_Graveler', '076_Golem', '077_Ponyta',\n",
    " '078_Rapidash', '079_Slowpoke', '080_Slowbro', '081_Magnemite', '082_Magneton', \"083_Farfetch'd\", '084_Doduo',\n",
    " '085_Dodrio', '086_Seel', '087_Dewgong', '088_Grimer', '089_Muk', '090_Shellder', '091_Cloyster', '092_Gastly',\n",
    " '093_Haunter', '094_Gengar', '095_Onix', '096_Drowzee', '097_Hypno', '098_Krabby', '099_Kingler', '100_Voltorb',\n",
    " '101_Electrode', '102_Exeggcute', '103_Exeggutor', '104_Cubone', '105_Marowak', '106_Hitmonlee', '107_Hitmonchan',\n",
    " '108_Lickitung', '109_Koffing', '110_Weezing', '111_Rhyhorn', '112_Rhydon', '113_Chansey', '114_Tangela',\n",
    " '115_Kangaskhan', '116_Horsea', '117_Seadra', '118_Goldeen', '119_Seaking', '120_Staryu', '121_Starmie',\n",
    " '122_Mr. Mime', '123_Scyther', '124_Jynx', '125_Electabuzz', '126_Magmar', '127_Pinsir', '128_Tauros',\n",
    " '129_Magikarp', '130_Gyarados', '131_Lapras', '132_Ditto', '133_Eevee', '134_Vaporeon', '135_Jolteon',\n",
    " '136_Flareon', '137_Porygon', '138_Omanyte', '139_Omastar', '140_Kabuto', '141_Kabutops', '142_Aerodactyl',\n",
    " '143_Snorlax', '144_Articuno', '145_Zapdos', '146_Moltres', '147_Dratini', '148_Dragonair', '149_Dragonite',\n",
    " '150_Mewtwo', '151_Mew', '152_Chikorita', '153_Bayleef', '154_Meganium', '155_Cyndaquil', '156_Quilava', '157_Typhlosion',\n",
    " '158_Totodile', '159_Croconaw', '160_Feraligatr', '161_Sentret', '162_Furret', '163_Hoothoot', '164_Noctowl',\n",
    " '165_Ledyba', '166_Ledian', '167_Spinarak', '168_Ariados', '169_Crobat', '170_Chinchou', '171_Lanturn', '172_Pichu',\n",
    " '173_Cleffa', '174_Igglybuff', '175_Togepi', '176_Togetic', '177_Natu', '178_Xatu', '179_Mareep', '180_Flaaffy',\n",
    " '181_Ampharos', '182_Bellossom', '183_Marill', '184_Azumarill', '185_Sudowoodo', '186_Politoed', '187_Hoppip',\n",
    " '188_Skiploom', '189_Jumpluff', '190_Aipom', '191_Sunkern', '192_Sunflora', '193_Yanma', '194_Wooper', '195_Quagsire',\n",
    " '196_Espeon', '197_Umbreon', '198_Murkrow', '199_Slowking', '200_Misdreavus', '201_Unown', '202_Wobbuffet', '203_Girafarig',\n",
    " '204_Pineco', '205_Forretress', '206_Dunsparce', '207_Gligar', '208_Steelix', '209_Snubbull', '210_Granbull',\n",
    " '211_Qwilfish', '212_Scizor', '213_Shuckle', '214_Heracross', '215_Sneasel', '216_Teddiursa', '217_Ursaring',\n",
    " '218_Slugma', '219_Magcargo', '220_Swinub', '221_Piloswine', '222_Corsola', '223_Remoraid', '224_Octillery',\n",
    " '225_Delibird', '226_Mantine', '227_Skarmory', '228_Houndour', '229_Houndoom', '230_Kingdra', '231_Phanpy',\n",
    " '232_Donphan', '233_Porygon2', '234_Stantler', '235_Smeargle', '236_Tyrogue', '237_Hitmontop', '238_Smoochum',\n",
    " '239_Elekid', '240_Magby', '241_Miltank', '242_Blissey', '243_Raikou', '244_Entei', '245_Suicune', '246_Larvitar',\n",
    " '247_Pupitar', '248_Tyranitar', '249_Lugia', '250_Ho-Oh', '251_Celebi', '252_Treecko', '253_Grovyle', '254_Sceptile',\n",
    " '255_Torchic', '256_Combusken', '257_Blaziken', '258_Mudkip', '259_Marshtomp', '260_Swampert', '261_Poochyena',\n",
    " '262_Mightyena', '263_Zigzagoon', '264_Linoone', '265_Wurmple', '266_Silcoon', '267_Beautifly', '268_Cascoon',\n",
    " '269_Dustox', '270_Lotad', '271_Lombre', '272_Ludicolo', '273_Seedot', '274_Nuzleaf', '275_Shiftry', '276_Taillow',\n",
    " '277_Swellow', '278_Wingull', '279_Pelipper', '280_Ralts', '281_Kirlia', '282_Gardevoir', '283_Surskit', '284_Masquerain',\n",
    " '285_Shroomish', '286_Breloom', '287_Slakoth', '288_Vigoroth', '289_Slaking', '290_Nincada', '291_Ninjask',\n",
    " '292_Shedinja', '293_Whismur', '294_Loudred', '295_Exploud', '296_Makuhita', '297_Hariyama', '298_Azurill',\n",
    " '299_Nosepass', '300_Skitty', '301_Delcatty', '302_Sableye', '303_Mawile', '304_Aron', '305_Lairon', '306_Aggron',\n",
    " '307_Meditite', '308_Medicham', '309_Electrike', '310_Manectric', '311_Plusle', '312_Minun', '313_Volbeat',\n",
    " '314_Illumise', '315_Roselia', '316_Gulpin', '317_Swalot', '318_Carvanha', '319_Sharpedo', '320_Wailmer',\n",
    " '321_Wailord', '322_Numel', '323_Camerupt', '324_Torkoal', '325_Spoink', '326_Grumpig', '327_Spinda',\n",
    " '328_Trapinch', '329_Vibrava', '330_Flygon', '331_Cacnea', '332_Cacturne', '333_Swablu', '334_Altaria', '335_Zangoose',\n",
    " '336_Seviper', '337_Lunatone', '338_Solrock', '339_Barboach', '340_Whiscash', '341_Corphish', '342_Crawdaunt',\n",
    " '343_Baltoy', '344_Claydol', '345_Lileep', '346_Cradily', '347_Anorith', '348_Armaldo', '349_Feebas', '350_Milotic',\n",
    " '351_Castform', '352_Kecleon', '353_Shuppet', '354_Banette', '355_Duskull', '356_Dusclops', '357_Tropius', '358_Chimecho',\n",
    " '359_Absol', '360_Wynaut', '361_Snorunt', '362_Glalie', '363_Spheal', '364_Sealeo', '365_Walrein', '366_Clamperl',\n",
    " '367_Huntail', '368_Gorebyss', '369_Relicanth', '370_Luvdisc', '371_Bagon', '372_Shelgon', '373_Salamence', '374_Beldum',\n",
    " '375_Metang', '376_Metagross', '377_Regirock', '378_Regice', '379_Registeel', '380_Latias', '381_Latios', '382_Kyogre',\n",
    " '383_Groudon', '384_Rayquaza', '385_Jirachi', '386_Deoxys', '387_Turtwig', '388_Grotle', '389_Torterra', '390_Chimchar',\n",
    " '391_Monferno', '392_Infernape', '393_Piplup', '394_Prinplup', '395_Empoleon', '396_Starly', '397_Staravia', '398_Staraptor',\n",
    " '399_Bidoof', '400_Bibarel', '401_Kricketot', '402_Kricketune', '403_Shinx', '404_Luxio', '405_Luxray',\n",
    " '406_Budew', '407_Roserade', '408_Cranidos', '409_Rampardos', '410_Shieldon', '411_Bastiodon', '412_Burmy', '413_Wormadam',\n",
    " '414_Mothim', '415_Combee', '416_Vespiquen', '417_Pachirisu', '418_Buizel', '419_Floatzel', '420_Cherubi', '421_Cherrim',\n",
    " '422_Shellos', '423_Gastrodon', '424_Ambipom', '425_Drifloon', '426_Drifblim', '427_Buneary', '428_Lopunny',\n",
    " '429_Mismagius', '430_Honchkrow', '431_Glameow', '432_Purugly', '433_Chingling', '434_Stunky', '435_Skuntank',\n",
    " '436_Bronzor', '437_Bronzong', '438_Bonsly', '439_Mime Jr.', '440_Happiny', '441_Chatot', '442_Spiritomb', '443_Gible',\n",
    " '444_Gabite', '445_Garchomp', '446_Munchlax', '447_Riolu', '448_Lucario', '449_Hippopotas', '450_Hippowdon', '451_Skorupi',\n",
    " '452_Drapion', '453_Croagunk', '454_Toxicroak', '455_Carnivine', '456_Finneon', '457_Lumineon', '458_Mantyke',\n",
    " '459_Snover', '460_Abomasnow', '461_Weavile', '462_Magnezone', '463_Lickilicky', '464_Rhyperior', '465_Tangrowth',\n",
    " '466_Electivire', '467_Magmortar', '468_Togekiss', '469_Yanmega', '470_Leafeon', '471_Glaceon', '472_Gliscor', '473_Mamoswine',\n",
    " '474_Porygon-Z', '475_Gallade', '476_Probopass', '477_Dusknoir', '478_Froslass', '479_Rotom', '480_Uxie', '481_Mesprit',\n",
    " '482_Azelf', '483_Dialga', '484_Palkia', '485_Heatran', '486_Regigigas', '487_Giratina', '488_Cresselia', '489_Phione',\n",
    " '490_Manaphy', '491_Darkrai', '492_Shaymin', '493_Arceus', '494_Victini', '495_Snivy', '496_Servine', '497_Serperior', '498_Tepig',\n",
    " '499_Pignite', '500_Emboar', '501_Oshawott', '502_Dewott', '503_Samurott', '504_Patrat', '505_Watchog',\n",
    " '506_Lillipup', '507_Herdier', '508_Stoutland', '509_Purrloin', '510_Liepard', '511_Pansage', '512_Simisage',\n",
    " '513_Pansear', '514_Simisear', '515_Panpour', '516_Simipour', '517_Munna', '518_Musharna', '519_Pidove', '520_Tranquill',\n",
    " '521_Unfezant', '522_Blitzle', '523_Zebstrika', '524_Roggenrola', '525_Boldore', '526_Gigalith', '527_Woobat',\n",
    " '528_Swoobat', '529_Drilbur', '530_Excadrill', '531_Audino', '532_Timburr', '533_Gurdurr', '534_Conkeldurr',\n",
    " '535_Tympole', '536_Palpitoad', '537_Seismitoad', '538_Throh', '539_Sawk', '540_Sewaddle', '541_Swadloon', '542_Leavanny',\n",
    " '543_Venipede', '544_Whirlipede', '545_Scolipede', '546_Cottonee', '547_Whimsicott', '548_Petilil', '549_Lilligant', \n",
    " '550_Basculin', '551_Sandile', '552_Krokorok', '553_Krookodile', '554_Darumaka', '555_Darmanitan', '556_Maractus',\n",
    " '557_Dwebble', '558_Crustle', '559_Scraggy', '560_Scrafty', '561_Sigilyph', '562_Yamask', '563_Cofagrigus',\n",
    " '564_Tirtouga', '565_Carracosta', '566_Archen', '567_Archeops', '568_Trubbish', '569_Garbodor', '570_Zorua', '571_Zoroark',\n",
    " '572_Minccino', '573_Cinccino', '574_Gothita', '575_Gothorita', '576_Gothitelle', '577_Solosis',\n",
    " '578_Duosion', '579_Reuniclus', '580_Ducklett', '581_Swanna', '582_Vanillite', '583_Vanillish', '584_Vanilluxe',\n",
    " '585_Deerling', '586_Sawsbuck', '587_Emolga', '588_Karrablast', '589_Escavalier', '590_Foongus', '591_Amoonguss',\n",
    " '592_Frillish', '593_Jellicent', '594_Alomomola', '595_Joltik', '596_Galvantula', '597_Ferroseed', '598_Ferrothorn',\n",
    " '599_Klink', '600_Klang', '601_Klinklang', '602_Tynamo', '603_Eelektrik', '604_Eelektross', '605_Elgyem',\n",
    " '606_Beheeyem', '607_Litwick', '608_Lampent', '609_Chandelure', '610_Axew', '611_Fraxure', '612_Haxorus', '613_Cubchoo',\n",
    " '614_Beartic', '615_Cryogonal', '616_Shelmet', '617_Accelgor', '618_Stunfisk', '619_Mienfoo', '620_Mienshao',\n",
    " '621_Druddigon', '622_Golett', '623_Golurk', '624_Pawniard', '625_Bisharp', '626_Bouffalant', '627_Rufflet',\n",
    " '628_Braviary', '629_Vullaby', '630_Mandibuzz', '631_Heatmor', '632_Durant', '633_Deino', '634_Zweilous',\n",
    " '635_Hydreigon', '636_Larvesta', '637_Volcarona', '638_Cobalion', '639_Terrakion', '640_Virizion', '641_Tornadus',\n",
    " '642_Thundurus', '643_Reshiram', '644_Zekrom', '645_Landorus', '646_Kyurem', '647_Keldeo', '648_Meloetta', '649_Genesect',\n",
    " '650_Chespin', '651_Quilladin', '652_Chesnaught', '653_Fennekin', '654_Braixen', '655_Delphox', '656_Froakie',\n",
    " '657_Frogadier', '658_Greninja', '659_Bunnelby', '660_Diggersby', '661_Fletchling', '662_Fletchinder',\n",
    " '663_Talonflame', '664_Scatterbug', '665_Spewpa', '666_Vivillon', '667_Litleo', '668_Pyroar', '669_Flabébé',\n",
    " '670_Floette', '671_Florges', '672_Skiddo', '673_Gogoat', '674_Pancham', '675_Pangoro', '676_Furfrou', '677_Espurr',\n",
    " '678_Meowstic', '679_Honedge', '680_Doublade', '681_Aegislash', '682_Spritzee', '683_Aromatisse', '684_Swirlix',\n",
    " '685_Slurpuff', '686_Inkay', '687_Malamar', '688_Binacle', '689_Barbaracle', '690_Skrelp', '691_Dragalge', '692_Clauncher',\n",
    " '693_Clawitzer', '694_Helioptile', '695_Heliolisk', '696_Tyrunt', '697_Tyrantrum', '698_Amaura', '699_Aurorus', \n",
    " '700_Sylveon', '701_Hawlucha', '702_Dedenne', '703_Carbink', '704_Goomy', '705_Sliggoo', '706_Goodra', '707_Klefki',\n",
    " '708_Phantump', '709_Trevenant', '710_Pumpkaboo', '711_Gourgeist', '712_Bergmite', '713_Avalugg',\n",
    " '714_Noibat', '715_Noivern', '716_Xerneas', '717_Yveltal', '718_Zygarde', '719_Diancie', '720_Hoopa', '721_Volcanion',\n",
    " '722_Rowlet', '723_Dartrix', '724_Decidueye', '725_Litten', '726_Torracat', '727_Incineroar', '728_Popplio',\n",
    " '729_Brionne', '730_Primarina', '731_Pikipek', '732_Trumbeak', '733_Toucannon', '734_Yungoos', '735_Gumshoos',\n",
    " '736_Grubbin', '737_Charjabug', '738_Vikavolt', '739_Crabrawler', '740_Crabominable', '741_Oricorio', '742_Cutiefly',\n",
    " '743_Ribombee', '744_Rockruff', '745_Lycanroc', '746_Wishiwashi', '747_Mareanie', '748_Toxapex', '749_Mudbray',\n",
    " '750_Mudsdale', '751_Dewpider', '752_Araquanid', '753_Fomantis', '754_Lurantis', '755_Morelull', '756_Shiinotic',\n",
    " '757_Salandit', '758_Salazzle', '759_Stufful', '760_Bewear', '761_Bounsweet', '762_Steenee', '763_Tsareena',\n",
    " '764_Comfey', '765_Oranguru', '766_Passimian', '767_Wimpod', '768_Golisopod', '769_Sandygast', '770_Palossand',\n",
    " '771_Pyukumuku', '772_Type_Null', '773_Silvally', '774_Minior', '775_Komala', '776_Turtonator', '777_Togedemaru',\n",
    " '778_Mimikyu', '779_Bruxish', '780_Drampa', '781_Dhelmise', '782_Jangmo-o', '783_Hakamo-o', '784_Kommo-o',\n",
    " '785_Tapu Koko', '786_Tapu Lele', '787_Tapu Bulu', '788_Tapu Fini', '789_Cosmog', '790_Cosmoem', '791_Solgaleo',\n",
    " '792_Lunala', '793_Nihilego', '794_Buzzwole', '795_Pheromosa', '796_Xurkitree', '797_Celesteela', '798_Kartana',\n",
    " '799_Guzzlord', '800_Necrozma', '801_Magearna', '802_Marshadow', '803_Poipole', '804_Naganadel', '805_Stakataka',\n",
    " '806_Blacephalon', '807_Zeraora', '808_Meltan', '809_Melmetal', '810_Grookey', '811_Thwackey', '812_Rillaboom',\n",
    " '813_Scorbunny', '814_Raboot', '815_Cinderace', '816_Sobble', '817_Drizzile', '818_Inteleon', '819_Skwovet',\n",
    " '820_Greedent', '821_Rookidee', '822_Corvisquire', '823_Corviknight', '824_Blipbug', '825_Dottler', '826_Orbeetle',\n",
    " '827_Nickit', '828_Thievul', '829_Gossifleur', '830_Eldegoss', '831_Wooloo', '832_Dubwool', '833_Chewtle', '834_Drednaw',\n",
    " '835_Yamper', '836_Boltund', '837_Rolycoly', '838_Carkol', '839_Coalossal', '840_Applin', '841_Flapple', '842_Appletun',\n",
    " '843_Silicobra', '844_Sandaconda', '845_Cramorant', '846_Arrokuda', '847_Barraskewda', '848_Toxel', '849_Toxtricity',\n",
    " '850_Sizzlipede', '851_Centiskorch', '852_Clobbopus', '853_Grapploct', '854_Sinistea', '855_Polteageist',\n",
    " '856_Hatenna', '857_Hattrem', '858_Hatterene', '859_Impidimp', '860_Morgrem', '861_Grimmsnarl', '862_Obstagoon',\n",
    " '863_Perrserker', '864_Cursola', \"865_Sirfetch'd\", '866_Mr. Rime', '867_Runerigus', '868_Milcery', '869_Alcremie',\n",
    " '870_Falinks', '871_Pincurchin', '872_Snom', '873_Frosmoth', '874_Stonjourner', '875_Eiscue', '876_Indeedee',\n",
    " '877_Morpeko', '878_Cufant', '879_Copperajah', '880_Dracozolt', '881_Arctozolt', '882_Dracovish', '883_Arctovish',\n",
    " '884_Duraludon', '885_Dreepy', '886_Drakloak', '887_Dragapult', '888_Zacian', '889_Zamazenta', '890_Eternatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we filter the images which bigger than (120, 120, 3)\n",
      "We have 813 pokemon containing more than 3 images\n"
     ]
    }
   ],
   "source": [
    "# if image smaller than x, then we will not use them\n",
    "# this section shows how many images will left in each pokemon\n",
    "filter_standard = (120, 120, 3)\n",
    "\n",
    "# filter_df = pd.DataFrame(columns = ['pokemon name', 'amount'])\n",
    "count_list = []\n",
    "\n",
    "for name in folder_name_list:\n",
    "    path = './Pokemon Dataset (convert to png files)/{}'.format(name)\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    count = 0\n",
    "    for i in range(len(onlyfiles)):\n",
    "        image = np.asarray(Image.open('./Pokemon Dataset (convert to png files)/{}/{}'.format(name, onlyfiles[i])))\n",
    "        if image.shape > filter_standard:\n",
    "            count += 1\n",
    "    count_list.append(count)\n",
    "\n",
    "print('When we filter the images which bigger than {}'.format(filter_standard))        \n",
    "print('We have {} pokemon containing more than 3 images'.format(len([i for i in count_list if i >= 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pokemon name</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001_Bulbasaur</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_Ivysaur</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003_Venusaur</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004_Charmander</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005_Charmeleon</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886_Drakloak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887_Dragapult</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888_Zacian</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889_Zamazenta</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890_Eternatus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>890 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pokemon name  amount\n",
       "0     001_Bulbasaur      22\n",
       "1       002_Ivysaur      13\n",
       "2      003_Venusaur      17\n",
       "3    004_Charmander      21\n",
       "4    005_Charmeleon      12\n",
       "..              ...     ...\n",
       "885    886_Drakloak       1\n",
       "886   887_Dragapult       1\n",
       "887      888_Zacian       2\n",
       "888   889_Zamazenta       2\n",
       "889   890_Eternatus       5\n",
       "\n",
       "[890 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df = pd.DataFrame({'pokemon name': folder_name_list, 'amount': count_list})\n",
    "filter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dataset we need for building CNN below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "name_list = []\n",
    "classes = 0\n",
    "for name in folder_name_list:\n",
    "    path = './Pokemon Dataset (convert to png files)/{}'.format(name)\n",
    "    if os.path.exists(path):\n",
    "        onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "        for i in range(len(onlyfiles)):\n",
    "            image = np.asarray(Image.open('./Pokemon Dataset (convert to png files)/{}/{}'.format(name, onlyfiles[i])))\n",
    "            # if image size is bigger than the standard and the image amount of that pokemon is more than or equal to 3\n",
    "            if (image.shape > filter_standard) & (folder_name_list.index(name) not in filter_df[filter_df['amount'] < 3].index):\n",
    "                temp = Image.open('./Pokemon Dataset (convert to png files)/{}/{}'.format(name, onlyfiles[i])).resize((120,120), Image.ANTIALIAS)\n",
    "                x.append(np.asarray(temp))\n",
    "                y.append(classes)\n",
    "                name_list.append(name)\n",
    "        classes += 1\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 812, 812, 812])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_encode = []\n",
    "for i in y:\n",
    "    for j in np.unique(y):\n",
    "        if i == j:\n",
    "            class_encode.append(list(np.unique(y)).index(j))\n",
    "np.array(class_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "train_images, test_images, train_labels, test_labels = train_test_split(x, class_encode, test_size = 0.2, random_state = 42, stratify = class_encode)\n",
    "# # Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "train_labels_org = train_labels\n",
    "test_labels_org = test_labels\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "train_labels = np_utils.to_categorical(train_labels)\n",
    "test_labels = np_utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad and flip the data to get more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_addons as tfa\n",
    "\n",
    "# train_images_list = []\n",
    "# train_labels_list = []\n",
    "# for i in range(len(train_images)):\n",
    "#     # original image padding into bigger image\n",
    "#     pad = tf.image.pad_to_bounding_box(train_images[i], 4, 4, 128, 128)\n",
    "#     pad_arr = np.asarray(pad)\n",
    "#     train_images_list.append(pad_arr)\n",
    "#     train_labels_list.append(train_labels[i])\n",
    "    \n",
    "#     # filp image left and right \n",
    "#     flip = tf.image.flip_left_right(pad)\n",
    "#     flip = np.asarray(flip)\n",
    "#     train_images_list.append(flip)\n",
    "#     train_labels_list.append(train_labels[i])\n",
    "    \n",
    "#     # crop\n",
    "#     crop = tf.image.crop_to_bounding_box(train_images[i], 10, 10, 110, 110) \n",
    "#     crop = tf.image.pad_to_bounding_box(crop, 4, 4, 128, 128)\n",
    "#     crop = np.asarray(crop) \n",
    "#     train_images_list.append(crop)\n",
    "#     train_labels_list.append(train_labels[i])\n",
    "    \n",
    "#     # rotation left + filp image left and right \n",
    "#     rotate_left = tfa.image.rotate(pad, tf.constant(np.pi/8))\n",
    "#     rotate_left = np.asarray(rotate_left)\n",
    "#     train_images_list.append(rotate_left)\n",
    "#     train_labels_list.append(train_labels[i])\n",
    "    \n",
    "# #     rotate_left_flip = tf.image.flip_left_right(rotate_left)\n",
    "# #     rotate_left_flip = np.asarray(rotate_left_flip)\n",
    "# #     train_images_list.append(rotate_left_flip)\n",
    "# #     train_labels_list.append(train_labels[i])\n",
    "    \n",
    "    \n",
    "#     # rotation right + filp image left and right \n",
    "#     rotation_right = tfa.image.rotate(pad, -tf.constant(np.pi/8))\n",
    "#     rotation_right = np.asarray(rotation_right)\n",
    "#     train_images_list.append(rotation_right)\n",
    "#     train_labels_list.append(train_labels[i])\n",
    "    \n",
    "# #     rotate_left_flip = tf.image.flip_left_right(rotation_right)\n",
    "# #     rotate_left_flip = np.asarray(rotate_left_flip)\n",
    "# #     train_images_list.append(rotate_left_flip)\n",
    "# #     train_labels_list.append(train_labels[i])\n",
    "    \n",
    "# train_images = np.asarray(train_images_list)\n",
    "# train_labels = np.asarray(train_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_images_list = []\n",
    "# for i in range(len(test_images)):\n",
    "#     # original image padding into bigger image\n",
    "#     pad = tf.image.pad_to_bounding_box(test_images[i], 4, 4, 128, 128)\n",
    "#     pad_arr = np.asarray(pad)\n",
    "#     test_images_list.append(pad_arr)\n",
    "\n",
    "# test_images = np.asarray(test_images_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 (Model 5 from 3.CNN but more epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 110, 110, 48)      17472     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 54, 54, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 128)       153728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 192)       221376    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 192)       331968    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 128)       221312    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              37750784  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              2049000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 813)               813813    \n",
      "=================================================================\n",
      "Total params: 45,755,805\n",
      "Trainable params: 45,755,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(48,(11,11), padding = 'valid', activation='relu', input_shape = (120, 120, 3)))\n",
    "model.add(layers.MaxPool2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128,(5,5), padding = 'same', activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(192,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model.add(layers.Conv2D(192,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model.add(layers.Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(2048, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(2048, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(1000, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(len(np.unique(y)), activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRICS = [\n",
    "# #       metrics.TruePositives(name='tp'),\n",
    "# #       metrics.FalsePositives(name='fp'),\n",
    "# #       metrics.TrueNegatives(name='tn'),\n",
    "# #       metrics.FalseNegatives(name='fn'), \n",
    "#       metrics.CategoricalAccuracy(name='accuracy'),\n",
    "# #       metrics.CategoricalCrossentropy(name='crossentropy'),\n",
    "#       metrics.Precision(name='precision'),\n",
    "#       metrics.Recall(name='recall'),\n",
    "#       metrics.AUC(name='auc'),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# history = model.fit_generator(img_gen.flow(train_images*255, train_labels, batch_size = 16),\n",
    "#                                       steps_per_epoch = len(train_images)/16, validation_data = (test_images,test_labels), epochs = 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-9422a8a8c13a>:4: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 6.6990 - accuracy: 0.0017 - val_loss: 6.6812 - val_accuracy: 0.0125\n",
      "Epoch 2/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 6.6611 - accuracy: 0.0057 - val_loss: 6.6034 - val_accuracy: 0.0125\n",
      "Epoch 3/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.6144 - accuracy: 0.0103 - val_loss: 6.5561 - val_accuracy: 0.0125\n",
      "Epoch 4/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.5759 - accuracy: 0.0121 - val_loss: 6.5437 - val_accuracy: 0.0125\n",
      "Epoch 5/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.5531 - accuracy: 0.0134 - val_loss: 6.5007 - val_accuracy: 0.0125\n",
      "Epoch 6/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.5346 - accuracy: 0.0154 - val_loss: 6.4733 - val_accuracy: 0.0184\n",
      "Epoch 7/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.4965 - accuracy: 0.0176 - val_loss: 6.4269 - val_accuracy: 0.0213\n",
      "Epoch 8/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 6.4759 - accuracy: 0.0196 - val_loss: 6.3818 - val_accuracy: 0.0213\n",
      "Epoch 9/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 6.4454 - accuracy: 0.0220 - val_loss: 6.3446 - val_accuracy: 0.0213\n",
      "Epoch 10/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 6.4293 - accuracy: 0.0191 - val_loss: 6.3115 - val_accuracy: 0.0213\n",
      "Epoch 11/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.3816 - accuracy: 0.0233 - val_loss: 6.2881 - val_accuracy: 0.0213\n",
      "Epoch 12/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.3626 - accuracy: 0.0222 - val_loss: 6.2707 - val_accuracy: 0.0213\n",
      "Epoch 13/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.3190 - accuracy: 0.0198 - val_loss: 6.2024 - val_accuracy: 0.0235\n",
      "Epoch 14/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.2906 - accuracy: 0.0226 - val_loss: 6.1686 - val_accuracy: 0.0264\n",
      "Epoch 15/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.2570 - accuracy: 0.0231 - val_loss: 6.1397 - val_accuracy: 0.0316\n",
      "Epoch 16/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 6.2235 - accuracy: 0.0233 - val_loss: 6.0953 - val_accuracy: 0.0294\n",
      "Epoch 17/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.1889 - accuracy: 0.0241 - val_loss: 6.0816 - val_accuracy: 0.0323\n",
      "Epoch 18/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.1570 - accuracy: 0.0270 - val_loss: 5.9976 - val_accuracy: 0.0316\n",
      "Epoch 19/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.1229 - accuracy: 0.0281 - val_loss: 5.9593 - val_accuracy: 0.0374\n",
      "Epoch 20/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.0965 - accuracy: 0.0279 - val_loss: 5.9397 - val_accuracy: 0.0419\n",
      "Epoch 21/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 6.0612 - accuracy: 0.0345 - val_loss: 5.8916 - val_accuracy: 0.0433\n",
      "Epoch 22/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 6.0149 - accuracy: 0.0354 - val_loss: 5.8591 - val_accuracy: 0.0507\n",
      "Epoch 23/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 5.9830 - accuracy: 0.0373 - val_loss: 5.8077 - val_accuracy: 0.0485\n",
      "Epoch 24/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 5.9413 - accuracy: 0.0376 - val_loss: 5.7497 - val_accuracy: 0.0587\n",
      "Epoch 25/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 5.9081 - accuracy: 0.0444 - val_loss: 5.7198 - val_accuracy: 0.0683\n",
      "Epoch 26/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 5.8483 - accuracy: 0.0474 - val_loss: 5.6412 - val_accuracy: 0.0698\n",
      "Epoch 27/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 5.8223 - accuracy: 0.0540 - val_loss: 5.6332 - val_accuracy: 0.0764\n",
      "Epoch 28/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 5.7767 - accuracy: 0.0544 - val_loss: 5.5673 - val_accuracy: 0.0815\n",
      "Epoch 29/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 5.7224 - accuracy: 0.0566 - val_loss: 5.5231 - val_accuracy: 0.0844\n",
      "Epoch 30/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 5.6699 - accuracy: 0.0628 - val_loss: 5.4652 - val_accuracy: 0.0896\n",
      "Epoch 31/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 5.6222 - accuracy: 0.0670 - val_loss: 5.3647 - val_accuracy: 0.0991\n",
      "Epoch 32/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 5.5822 - accuracy: 0.0659 - val_loss: 5.3099 - val_accuracy: 0.1065\n",
      "Epoch 33/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 5.5125 - accuracy: 0.0760 - val_loss: 5.2451 - val_accuracy: 0.1116\n",
      "Epoch 34/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 5.4679 - accuracy: 0.0786 - val_loss: 5.2238 - val_accuracy: 0.1197\n",
      "Epoch 35/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 5.4350 - accuracy: 0.0815 - val_loss: 5.1311 - val_accuracy: 0.1241\n",
      "Epoch 36/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 5.3660 - accuracy: 0.0854 - val_loss: 5.0830 - val_accuracy: 0.1314\n",
      "Epoch 37/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 5.2930 - accuracy: 0.0924 - val_loss: 5.0057 - val_accuracy: 0.1498\n",
      "Epoch 38/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 5.2748 - accuracy: 0.0944 - val_loss: 4.9267 - val_accuracy: 0.1498\n",
      "Epoch 39/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 5.2195 - accuracy: 0.0968 - val_loss: 4.8927 - val_accuracy: 0.1579\n",
      "Epoch 40/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 5.1284 - accuracy: 0.1034 - val_loss: 4.8012 - val_accuracy: 0.1637\n",
      "Epoch 41/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 5.1092 - accuracy: 0.1054 - val_loss: 4.7817 - val_accuracy: 0.1659\n",
      "Epoch 42/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 5.0296 - accuracy: 0.1148 - val_loss: 4.7085 - val_accuracy: 0.1872\n",
      "Epoch 43/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 4.9960 - accuracy: 0.1172 - val_loss: 4.6311 - val_accuracy: 0.1946\n",
      "Epoch 44/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 4.9338 - accuracy: 0.1216 - val_loss: 4.5899 - val_accuracy: 0.1968\n",
      "Epoch 45/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 4.8791 - accuracy: 0.1205 - val_loss: 4.5117 - val_accuracy: 0.2078\n",
      "Epoch 46/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 4.8427 - accuracy: 0.1298 - val_loss: 4.4426 - val_accuracy: 0.2166\n",
      "Epoch 47/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 4.7766 - accuracy: 0.1396 - val_loss: 4.3887 - val_accuracy: 0.2232\n",
      "Epoch 48/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 4.7017 - accuracy: 0.1443 - val_loss: 4.3180 - val_accuracy: 0.2305\n",
      "Epoch 49/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 4.6786 - accuracy: 0.1440 - val_loss: 4.2886 - val_accuracy: 0.2269\n",
      "Epoch 50/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 4.6286 - accuracy: 0.1574 - val_loss: 4.2167 - val_accuracy: 0.2445\n",
      "Epoch 51/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 4.5506 - accuracy: 0.1588 - val_loss: 4.1632 - val_accuracy: 0.2496\n",
      "Epoch 52/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 4.4934 - accuracy: 0.1721 - val_loss: 4.1410 - val_accuracy: 0.2614\n",
      "Epoch 53/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 4.4366 - accuracy: 0.1673 - val_loss: 4.0388 - val_accuracy: 0.2695\n",
      "Epoch 54/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 4.3902 - accuracy: 0.1776 - val_loss: 3.9944 - val_accuracy: 0.2790\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/340 [==============================] - 78s 227ms/step - loss: 4.3329 - accuracy: 0.1788 - val_loss: 3.9637 - val_accuracy: 0.2797\n",
      "Epoch 56/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 4.2780 - accuracy: 0.1888 - val_loss: 3.8637 - val_accuracy: 0.2841\n",
      "Epoch 57/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 4.2205 - accuracy: 0.1834 - val_loss: 3.8168 - val_accuracy: 0.2841\n",
      "Epoch 58/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 4.1902 - accuracy: 0.1968 - val_loss: 3.8003 - val_accuracy: 0.3040\n",
      "Epoch 59/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 4.1208 - accuracy: 0.2084 - val_loss: 3.7381 - val_accuracy: 0.3128\n",
      "Epoch 60/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 4.0583 - accuracy: 0.2117 - val_loss: 3.7044 - val_accuracy: 0.3209\n",
      "Epoch 61/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 3.9946 - accuracy: 0.2255 - val_loss: 3.6129 - val_accuracy: 0.3238\n",
      "Epoch 62/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 3.9802 - accuracy: 0.2238 - val_loss: 3.7097 - val_accuracy: 0.2988\n",
      "Epoch 63/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 3.9322 - accuracy: 0.2295 - val_loss: 3.5167 - val_accuracy: 0.3385\n",
      "Epoch 64/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 3.8549 - accuracy: 0.2402 - val_loss: 3.5326 - val_accuracy: 0.3465\n",
      "Epoch 65/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 3.8061 - accuracy: 0.2394 - val_loss: 3.4425 - val_accuracy: 0.3590\n",
      "Epoch 66/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 3.7697 - accuracy: 0.2545 - val_loss: 3.4156 - val_accuracy: 0.3605\n",
      "Epoch 67/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 3.7095 - accuracy: 0.2606 - val_loss: 3.3795 - val_accuracy: 0.3605\n",
      "Epoch 68/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 3.6699 - accuracy: 0.2618 - val_loss: 3.3397 - val_accuracy: 0.3722\n",
      "Epoch 69/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 3.6634 - accuracy: 0.2602 - val_loss: 3.3035 - val_accuracy: 0.3803\n",
      "Epoch 70/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 3.5889 - accuracy: 0.2710 - val_loss: 3.2443 - val_accuracy: 0.3825\n",
      "Epoch 71/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 3.5515 - accuracy: 0.2758 - val_loss: 3.2036 - val_accuracy: 0.3884\n",
      "Epoch 72/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 3.5093 - accuracy: 0.2771 - val_loss: 3.1971 - val_accuracy: 0.3957\n",
      "Epoch 73/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 3.4300 - accuracy: 0.2874 - val_loss: 3.0976 - val_accuracy: 0.4060\n",
      "Epoch 74/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 3.3755 - accuracy: 0.2960 - val_loss: 3.0747 - val_accuracy: 0.4046\n",
      "Epoch 75/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 3.3485 - accuracy: 0.3074 - val_loss: 3.0672 - val_accuracy: 0.3994\n",
      "Epoch 76/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 3.3247 - accuracy: 0.3089 - val_loss: 3.0272 - val_accuracy: 0.4185\n",
      "Epoch 77/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 3.2625 - accuracy: 0.3134 - val_loss: 2.9952 - val_accuracy: 0.4214\n",
      "Epoch 78/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 3.2005 - accuracy: 0.3189 - val_loss: 2.9510 - val_accuracy: 0.4280\n",
      "Epoch 79/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 3.1763 - accuracy: 0.3241 - val_loss: 2.9018 - val_accuracy: 0.4317\n",
      "Epoch 80/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 3.1379 - accuracy: 0.3331 - val_loss: 2.8625 - val_accuracy: 0.4391\n",
      "Epoch 81/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 3.0919 - accuracy: 0.3456 - val_loss: 2.8797 - val_accuracy: 0.4457\n",
      "Epoch 82/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 3.0457 - accuracy: 0.3426 - val_loss: 2.8391 - val_accuracy: 0.4501\n",
      "Epoch 83/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 2.9965 - accuracy: 0.3531 - val_loss: 2.7828 - val_accuracy: 0.4655\n",
      "Epoch 84/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 2.9631 - accuracy: 0.3682 - val_loss: 2.7645 - val_accuracy: 0.4655\n",
      "Epoch 85/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 2.9314 - accuracy: 0.3665 - val_loss: 2.8043 - val_accuracy: 0.4471\n",
      "Epoch 86/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 2.8820 - accuracy: 0.3718 - val_loss: 2.7203 - val_accuracy: 0.4750\n",
      "Epoch 87/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 2.8631 - accuracy: 0.3693 - val_loss: 2.7003 - val_accuracy: 0.4677\n",
      "Epoch 88/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 2.8058 - accuracy: 0.3849 - val_loss: 2.6660 - val_accuracy: 0.4772\n",
      "Epoch 89/500\n",
      "341/340 [==============================] - 79s 230ms/step - loss: 2.7209 - accuracy: 0.3979 - val_loss: 2.5752 - val_accuracy: 0.4875\n",
      "Epoch 90/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 2.7429 - accuracy: 0.3896 - val_loss: 2.5751 - val_accuracy: 0.4934\n",
      "Epoch 91/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 2.6498 - accuracy: 0.4117 - val_loss: 2.5716 - val_accuracy: 0.4912\n",
      "Epoch 92/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 2.6804 - accuracy: 0.4078 - val_loss: 2.5211 - val_accuracy: 0.5066\n",
      "Epoch 93/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 2.6023 - accuracy: 0.4196 - val_loss: 2.5429 - val_accuracy: 0.4949\n",
      "Epoch 94/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 2.5616 - accuracy: 0.4148 - val_loss: 2.4899 - val_accuracy: 0.5095\n",
      "Epoch 95/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 2.5726 - accuracy: 0.4212 - val_loss: 2.4417 - val_accuracy: 0.5191\n",
      "Epoch 96/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 2.5294 - accuracy: 0.4267 - val_loss: 2.4182 - val_accuracy: 0.5286\n",
      "Epoch 97/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 2.4546 - accuracy: 0.4422 - val_loss: 2.4334 - val_accuracy: 0.5235\n",
      "Epoch 98/500\n",
      "341/340 [==============================] - 79s 231ms/step - loss: 2.4571 - accuracy: 0.4381 - val_loss: 2.4488 - val_accuracy: 0.5191\n",
      "Epoch 99/500\n",
      "341/340 [==============================] - 79s 231ms/step - loss: 2.4152 - accuracy: 0.4506 - val_loss: 2.3870 - val_accuracy: 0.5250\n",
      "Epoch 100/500\n",
      "341/340 [==============================] - 79s 232ms/step - loss: 2.3966 - accuracy: 0.4605 - val_loss: 2.3326 - val_accuracy: 0.5411\n",
      "Epoch 101/500\n",
      "341/340 [==============================] - 79s 232ms/step - loss: 2.3334 - accuracy: 0.4631 - val_loss: 2.4094 - val_accuracy: 0.5176\n",
      "Epoch 102/500\n",
      "341/340 [==============================] - 79s 233ms/step - loss: 2.2897 - accuracy: 0.4774 - val_loss: 2.3028 - val_accuracy: 0.5426\n",
      "Epoch 103/500\n",
      "341/340 [==============================] - 79s 233ms/step - loss: 2.2700 - accuracy: 0.4831 - val_loss: 2.2949 - val_accuracy: 0.5485\n",
      "Epoch 104/500\n",
      "341/340 [==============================] - 79s 233ms/step - loss: 2.2700 - accuracy: 0.4802 - val_loss: 2.3080 - val_accuracy: 0.5433\n",
      "Epoch 105/500\n",
      "341/340 [==============================] - 79s 233ms/step - loss: 2.1707 - accuracy: 0.4936 - val_loss: 2.2421 - val_accuracy: 0.5624\n",
      "Epoch 106/500\n",
      "341/340 [==============================] - 80s 233ms/step - loss: 2.1919 - accuracy: 0.4921 - val_loss: 2.2026 - val_accuracy: 0.5631\n",
      "Epoch 107/500\n",
      "341/340 [==============================] - 80s 233ms/step - loss: 2.1603 - accuracy: 0.4930 - val_loss: 2.2788 - val_accuracy: 0.5470\n",
      "Epoch 108/500\n",
      "341/340 [==============================] - 80s 233ms/step - loss: 2.1023 - accuracy: 0.5095 - val_loss: 2.1978 - val_accuracy: 0.5734\n",
      "Epoch 109/500\n",
      "341/340 [==============================] - 80s 234ms/step - loss: 2.0593 - accuracy: 0.5079 - val_loss: 2.1670 - val_accuracy: 0.5771\n",
      "Epoch 110/500\n",
      "341/340 [==============================] - 80s 234ms/step - loss: 2.0793 - accuracy: 0.5176 - val_loss: 2.1763 - val_accuracy: 0.5639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/500\n",
      "341/340 [==============================] - 80s 233ms/step - loss: 2.0431 - accuracy: 0.5191 - val_loss: 2.1326 - val_accuracy: 0.5815\n",
      "Epoch 112/500\n",
      "341/340 [==============================] - 79s 233ms/step - loss: 2.0328 - accuracy: 0.5191 - val_loss: 2.1672 - val_accuracy: 0.5734\n",
      "Epoch 113/500\n",
      "341/340 [==============================] - 79s 233ms/step - loss: 1.9924 - accuracy: 0.5299 - val_loss: 2.1365 - val_accuracy: 0.5822\n",
      "Epoch 114/500\n",
      "341/340 [==============================] - 79s 233ms/step - loss: 2.0136 - accuracy: 0.5275 - val_loss: 2.1425 - val_accuracy: 0.5734\n",
      "Epoch 115/500\n",
      "341/340 [==============================] - 80s 233ms/step - loss: 1.9280 - accuracy: 0.5430 - val_loss: 2.1058 - val_accuracy: 0.5852\n",
      "Epoch 116/500\n",
      "341/340 [==============================] - 79s 233ms/step - loss: 1.9188 - accuracy: 0.5443 - val_loss: 2.0604 - val_accuracy: 0.5910\n",
      "Epoch 117/500\n",
      "341/340 [==============================] - 79s 233ms/step - loss: 1.8803 - accuracy: 0.5466 - val_loss: 2.0733 - val_accuracy: 0.5932\n",
      "Epoch 118/500\n",
      "341/340 [==============================] - 79s 233ms/step - loss: 1.8350 - accuracy: 0.5571 - val_loss: 2.0535 - val_accuracy: 0.5925\n",
      "Epoch 119/500\n",
      "341/340 [==============================] - 79s 232ms/step - loss: 1.8223 - accuracy: 0.5564 - val_loss: 2.0123 - val_accuracy: 0.6035\n",
      "Epoch 120/500\n",
      "341/340 [==============================] - 79s 232ms/step - loss: 1.7959 - accuracy: 0.5714 - val_loss: 2.0554 - val_accuracy: 0.5977\n",
      "Epoch 121/500\n",
      "341/340 [==============================] - 79s 232ms/step - loss: 1.7607 - accuracy: 0.5722 - val_loss: 2.0678 - val_accuracy: 0.5881\n",
      "Epoch 122/500\n",
      "341/340 [==============================] - 79s 232ms/step - loss: 1.7730 - accuracy: 0.5692 - val_loss: 2.0308 - val_accuracy: 0.5977\n",
      "Epoch 123/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 1.7190 - accuracy: 0.5832 - val_loss: 1.9792 - val_accuracy: 0.6101\n",
      "Epoch 124/500\n",
      "341/340 [==============================] - 79s 230ms/step - loss: 1.7513 - accuracy: 0.5676 - val_loss: 1.9808 - val_accuracy: 0.6123\n",
      "Epoch 125/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 1.6609 - accuracy: 0.5993 - val_loss: 2.0237 - val_accuracy: 0.6050\n",
      "Epoch 126/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 1.6779 - accuracy: 0.5880 - val_loss: 1.9852 - val_accuracy: 0.6094\n",
      "Epoch 127/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 1.6192 - accuracy: 0.6028 - val_loss: 1.9986 - val_accuracy: 0.6057\n",
      "Epoch 128/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 1.6146 - accuracy: 0.6008 - val_loss: 1.9343 - val_accuracy: 0.6204\n",
      "Epoch 129/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 1.5368 - accuracy: 0.6234 - val_loss: 1.9128 - val_accuracy: 0.6219\n",
      "Epoch 130/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 1.5765 - accuracy: 0.6131 - val_loss: 1.9393 - val_accuracy: 0.6204\n",
      "Epoch 131/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 1.5517 - accuracy: 0.6214 - val_loss: 1.8994 - val_accuracy: 0.6256\n",
      "Epoch 132/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 1.5235 - accuracy: 0.6260 - val_loss: 1.9124 - val_accuracy: 0.6197\n",
      "Epoch 133/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 1.5081 - accuracy: 0.6195 - val_loss: 1.9245 - val_accuracy: 0.6182\n",
      "Epoch 134/500\n",
      "341/340 [==============================] - 79s 230ms/step - loss: 1.4865 - accuracy: 0.6311 - val_loss: 1.9127 - val_accuracy: 0.6226\n",
      "Epoch 135/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 1.4714 - accuracy: 0.6302 - val_loss: 1.9134 - val_accuracy: 0.6270\n",
      "Epoch 136/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 1.4660 - accuracy: 0.6320 - val_loss: 1.8601 - val_accuracy: 0.6417\n",
      "Epoch 137/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 1.3676 - accuracy: 0.6553 - val_loss: 1.8861 - val_accuracy: 0.6270\n",
      "Epoch 138/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 1.4090 - accuracy: 0.6399 - val_loss: 1.8439 - val_accuracy: 0.6366\n",
      "Epoch 139/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.3766 - accuracy: 0.6539 - val_loss: 1.8892 - val_accuracy: 0.6329\n",
      "Epoch 140/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.3739 - accuracy: 0.6548 - val_loss: 1.8079 - val_accuracy: 0.6380\n",
      "Epoch 141/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 1.3098 - accuracy: 0.6631 - val_loss: 1.8350 - val_accuracy: 0.6483\n",
      "Epoch 142/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 1.3423 - accuracy: 0.6574 - val_loss: 1.8400 - val_accuracy: 0.6439\n",
      "Epoch 143/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.3141 - accuracy: 0.6583 - val_loss: 1.8506 - val_accuracy: 0.6366\n",
      "Epoch 144/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.2892 - accuracy: 0.6689 - val_loss: 1.8048 - val_accuracy: 0.6512\n",
      "Epoch 145/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.2646 - accuracy: 0.6739 - val_loss: 1.8018 - val_accuracy: 0.6432\n",
      "Epoch 146/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.2666 - accuracy: 0.6737 - val_loss: 1.8196 - val_accuracy: 0.6476\n",
      "Epoch 147/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.2193 - accuracy: 0.6807 - val_loss: 1.8456 - val_accuracy: 0.6446\n",
      "Epoch 148/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.2041 - accuracy: 0.6855 - val_loss: 1.8562 - val_accuracy: 0.6373\n",
      "Epoch 149/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.1940 - accuracy: 0.6911 - val_loss: 1.7875 - val_accuracy: 0.6549\n",
      "Epoch 150/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.2010 - accuracy: 0.6805 - val_loss: 1.7844 - val_accuracy: 0.6542\n",
      "Epoch 151/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.1883 - accuracy: 0.6924 - val_loss: 1.7765 - val_accuracy: 0.6535\n",
      "Epoch 152/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.1291 - accuracy: 0.7029 - val_loss: 1.8229 - val_accuracy: 0.6535\n",
      "Epoch 153/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.1092 - accuracy: 0.7147 - val_loss: 1.7925 - val_accuracy: 0.6571\n",
      "Epoch 154/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.1199 - accuracy: 0.7090 - val_loss: 1.7766 - val_accuracy: 0.6564\n",
      "Epoch 155/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.1136 - accuracy: 0.7068 - val_loss: 1.8158 - val_accuracy: 0.6461\n",
      "Epoch 156/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.0744 - accuracy: 0.7176 - val_loss: 1.7692 - val_accuracy: 0.6461\n",
      "Epoch 157/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.1246 - accuracy: 0.7047 - val_loss: 1.7400 - val_accuracy: 0.6630\n",
      "Epoch 158/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.0559 - accuracy: 0.7240 - val_loss: 1.7347 - val_accuracy: 0.6681\n",
      "Epoch 159/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.0267 - accuracy: 0.7260 - val_loss: 1.7552 - val_accuracy: 0.6557\n",
      "Epoch 160/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.0159 - accuracy: 0.7345 - val_loss: 1.7313 - val_accuracy: 0.6652\n",
      "Epoch 161/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 1.0045 - accuracy: 0.7387 - val_loss: 1.7330 - val_accuracy: 0.6733\n",
      "Epoch 162/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.9914 - accuracy: 0.7371 - val_loss: 1.7663 - val_accuracy: 0.6571\n",
      "Epoch 163/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.9936 - accuracy: 0.7326 - val_loss: 1.7717 - val_accuracy: 0.6601\n",
      "Epoch 164/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.9782 - accuracy: 0.7420 - val_loss: 1.7396 - val_accuracy: 0.6696\n",
      "Epoch 165/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.9510 - accuracy: 0.7426 - val_loss: 1.6915 - val_accuracy: 0.6777\n",
      "Epoch 166/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.9651 - accuracy: 0.7398 - val_loss: 1.7507 - val_accuracy: 0.6608\n",
      "Epoch 167/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.9454 - accuracy: 0.7468 - val_loss: 1.7438 - val_accuracy: 0.6608\n",
      "Epoch 168/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.9356 - accuracy: 0.7508 - val_loss: 1.7123 - val_accuracy: 0.6645\n",
      "Epoch 169/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.9241 - accuracy: 0.7573 - val_loss: 1.7209 - val_accuracy: 0.6652\n",
      "Epoch 170/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.8921 - accuracy: 0.7628 - val_loss: 1.7137 - val_accuracy: 0.6755\n",
      "Epoch 171/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.9000 - accuracy: 0.7539 - val_loss: 1.7478 - val_accuracy: 0.6711\n",
      "Epoch 172/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.8548 - accuracy: 0.7697 - val_loss: 1.7607 - val_accuracy: 0.6593\n",
      "Epoch 173/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.8681 - accuracy: 0.7602 - val_loss: 1.7452 - val_accuracy: 0.6615\n",
      "Epoch 174/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.8468 - accuracy: 0.7732 - val_loss: 1.7517 - val_accuracy: 0.6777\n",
      "Epoch 175/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.8762 - accuracy: 0.7600 - val_loss: 1.6955 - val_accuracy: 0.6828\n",
      "Epoch 176/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.8118 - accuracy: 0.7811 - val_loss: 1.7080 - val_accuracy: 0.6769\n",
      "Epoch 177/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.8023 - accuracy: 0.7786 - val_loss: 1.7440 - val_accuracy: 0.6718\n",
      "Epoch 178/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.8610 - accuracy: 0.7688 - val_loss: 1.6931 - val_accuracy: 0.6843\n",
      "Epoch 179/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.8062 - accuracy: 0.7769 - val_loss: 1.6810 - val_accuracy: 0.6828\n",
      "Epoch 180/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.7881 - accuracy: 0.7866 - val_loss: 1.7235 - val_accuracy: 0.6711\n",
      "Epoch 181/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.7696 - accuracy: 0.7923 - val_loss: 1.7648 - val_accuracy: 0.6791\n",
      "Epoch 182/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.7649 - accuracy: 0.7899 - val_loss: 1.7311 - val_accuracy: 0.6725\n",
      "Epoch 183/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.7475 - accuracy: 0.7914 - val_loss: 1.7230 - val_accuracy: 0.6733\n",
      "Epoch 184/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.7285 - accuracy: 0.7980 - val_loss: 1.7063 - val_accuracy: 0.6880\n",
      "Epoch 185/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.7357 - accuracy: 0.7951 - val_loss: 1.8348 - val_accuracy: 0.6696\n",
      "Epoch 186/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.7450 - accuracy: 0.7927 - val_loss: 1.7096 - val_accuracy: 0.6791\n",
      "Epoch 187/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.7289 - accuracy: 0.8028 - val_loss: 1.7364 - val_accuracy: 0.6777\n",
      "Epoch 188/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.6992 - accuracy: 0.8057 - val_loss: 1.6553 - val_accuracy: 0.6894\n",
      "Epoch 189/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.6813 - accuracy: 0.8138 - val_loss: 1.6836 - val_accuracy: 0.6799\n",
      "Epoch 190/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 0.7271 - accuracy: 0.8004 - val_loss: 1.6901 - val_accuracy: 0.6784\n",
      "Epoch 191/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.6848 - accuracy: 0.8112 - val_loss: 1.6670 - val_accuracy: 0.6982\n",
      "Epoch 192/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.6765 - accuracy: 0.8118 - val_loss: 1.7109 - val_accuracy: 0.6909\n",
      "Epoch 193/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.6561 - accuracy: 0.8155 - val_loss: 1.7330 - val_accuracy: 0.6814\n",
      "Epoch 194/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.6580 - accuracy: 0.8169 - val_loss: 1.6919 - val_accuracy: 0.6814\n",
      "Epoch 195/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.6674 - accuracy: 0.8162 - val_loss: 1.6645 - val_accuracy: 0.6924\n",
      "Epoch 196/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.6358 - accuracy: 0.8221 - val_loss: 1.6968 - val_accuracy: 0.6821\n",
      "Epoch 197/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.6581 - accuracy: 0.8101 - val_loss: 1.7257 - val_accuracy: 0.6843\n",
      "Epoch 198/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.6324 - accuracy: 0.8173 - val_loss: 1.7054 - val_accuracy: 0.6821\n",
      "Epoch 199/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 0.6146 - accuracy: 0.8219 - val_loss: 1.7667 - val_accuracy: 0.6733\n",
      "Epoch 200/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.6176 - accuracy: 0.8237 - val_loss: 1.6642 - val_accuracy: 0.6916\n",
      "Epoch 201/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.6073 - accuracy: 0.8270 - val_loss: 1.6466 - val_accuracy: 0.6887\n",
      "Epoch 202/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.5963 - accuracy: 0.8303 - val_loss: 1.6676 - val_accuracy: 0.6938\n",
      "Epoch 203/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.6283 - accuracy: 0.8245 - val_loss: 1.6915 - val_accuracy: 0.6836\n",
      "Epoch 204/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.5538 - accuracy: 0.8371 - val_loss: 1.7570 - val_accuracy: 0.6850\n",
      "Epoch 205/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.5751 - accuracy: 0.8391 - val_loss: 1.7444 - val_accuracy: 0.6821\n",
      "Epoch 206/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.5837 - accuracy: 0.8316 - val_loss: 1.7731 - val_accuracy: 0.6769\n",
      "Epoch 207/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.5845 - accuracy: 0.8388 - val_loss: 1.7736 - val_accuracy: 0.6894\n",
      "Epoch 208/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.5775 - accuracy: 0.8355 - val_loss: 1.6385 - val_accuracy: 0.7070\n",
      "Epoch 209/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.5485 - accuracy: 0.8476 - val_loss: 1.7518 - val_accuracy: 0.6777\n",
      "Epoch 210/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.5358 - accuracy: 0.8529 - val_loss: 1.6635 - val_accuracy: 0.6924\n",
      "Epoch 211/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.5288 - accuracy: 0.8496 - val_loss: 1.7210 - val_accuracy: 0.6836\n",
      "Epoch 212/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.5490 - accuracy: 0.8470 - val_loss: 1.7242 - val_accuracy: 0.6843\n",
      "Epoch 213/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.5257 - accuracy: 0.8492 - val_loss: 1.6853 - val_accuracy: 0.6916\n",
      "Epoch 214/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.5384 - accuracy: 0.8454 - val_loss: 1.6670 - val_accuracy: 0.6938\n",
      "Epoch 215/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.4969 - accuracy: 0.8608 - val_loss: 1.7992 - val_accuracy: 0.6762\n",
      "Epoch 216/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.4959 - accuracy: 0.8564 - val_loss: 1.6955 - val_accuracy: 0.6990\n",
      "Epoch 217/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.4869 - accuracy: 0.8652 - val_loss: 1.6464 - val_accuracy: 0.6931\n",
      "Epoch 218/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 0.5060 - accuracy: 0.8562 - val_loss: 1.7301 - val_accuracy: 0.6968\n",
      "Epoch 219/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 0.4791 - accuracy: 0.8621 - val_loss: 1.7299 - val_accuracy: 0.6946\n",
      "Epoch 220/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 0.4816 - accuracy: 0.8621 - val_loss: 1.7882 - val_accuracy: 0.6836\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/340 [==============================] - 78s 227ms/step - loss: 0.4908 - accuracy: 0.8601 - val_loss: 1.6691 - val_accuracy: 0.6909\n",
      "Epoch 222/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 0.4576 - accuracy: 0.8678 - val_loss: 1.7368 - val_accuracy: 0.6902\n",
      "Epoch 223/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 0.4805 - accuracy: 0.8628 - val_loss: 1.7669 - val_accuracy: 0.6784\n",
      "Epoch 224/500\n",
      "341/340 [==============================] - 78s 229ms/step - loss: 0.4578 - accuracy: 0.8705 - val_loss: 1.7166 - val_accuracy: 0.6836\n",
      "Epoch 225/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 0.4510 - accuracy: 0.8718 - val_loss: 1.6925 - val_accuracy: 0.6931\n",
      "Epoch 226/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 0.4440 - accuracy: 0.8707 - val_loss: 1.7176 - val_accuracy: 0.6975\n",
      "Epoch 227/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 0.4455 - accuracy: 0.8731 - val_loss: 1.6965 - val_accuracy: 0.7063\n",
      "Epoch 228/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.4257 - accuracy: 0.8806 - val_loss: 1.7536 - val_accuracy: 0.6953\n",
      "Epoch 229/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.4541 - accuracy: 0.8694 - val_loss: 1.7615 - val_accuracy: 0.6865\n",
      "Epoch 230/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.4477 - accuracy: 0.8705 - val_loss: 1.7522 - val_accuracy: 0.6931\n",
      "Epoch 231/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.4180 - accuracy: 0.8761 - val_loss: 1.7251 - val_accuracy: 0.6916\n",
      "Epoch 232/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.4220 - accuracy: 0.8828 - val_loss: 1.8048 - val_accuracy: 0.6924\n",
      "Epoch 233/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.4276 - accuracy: 0.8836 - val_loss: 1.6845 - val_accuracy: 0.7004\n",
      "Epoch 234/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.4135 - accuracy: 0.8790 - val_loss: 1.7587 - val_accuracy: 0.6909\n",
      "Epoch 235/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 0.4012 - accuracy: 0.8805 - val_loss: 1.6676 - val_accuracy: 0.7085\n",
      "Epoch 236/500\n",
      "341/340 [==============================] - 78s 230ms/step - loss: 0.4136 - accuracy: 0.8830 - val_loss: 1.6855 - val_accuracy: 0.7041\n",
      "Epoch 237/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 0.3919 - accuracy: 0.8849 - val_loss: 1.6657 - val_accuracy: 0.7048\n",
      "Epoch 238/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 0.3913 - accuracy: 0.8880 - val_loss: 1.7113 - val_accuracy: 0.6916\n",
      "Epoch 239/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 0.4167 - accuracy: 0.8841 - val_loss: 1.6395 - val_accuracy: 0.7019\n",
      "Epoch 240/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.3961 - accuracy: 0.8854 - val_loss: 1.7216 - val_accuracy: 0.6902\n",
      "Epoch 241/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.3668 - accuracy: 0.8917 - val_loss: 1.7892 - val_accuracy: 0.6938\n",
      "Epoch 242/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.3699 - accuracy: 0.8941 - val_loss: 1.6659 - val_accuracy: 0.7026\n",
      "Epoch 243/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.3784 - accuracy: 0.8880 - val_loss: 1.7543 - val_accuracy: 0.6982\n",
      "Epoch 244/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.3471 - accuracy: 0.9003 - val_loss: 1.9170 - val_accuracy: 0.6806\n",
      "Epoch 245/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3663 - accuracy: 0.8937 - val_loss: 1.7797 - val_accuracy: 0.6924\n",
      "Epoch 246/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.3762 - accuracy: 0.8942 - val_loss: 1.7207 - val_accuracy: 0.6997\n",
      "Epoch 247/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3621 - accuracy: 0.8937 - val_loss: 1.7071 - val_accuracy: 0.7012\n",
      "Epoch 248/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3763 - accuracy: 0.8896 - val_loss: 1.7002 - val_accuracy: 0.7019\n",
      "Epoch 249/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.3340 - accuracy: 0.9064 - val_loss: 1.9670 - val_accuracy: 0.6777\n",
      "Epoch 250/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3484 - accuracy: 0.9007 - val_loss: 1.8517 - val_accuracy: 0.6916\n",
      "Epoch 251/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3579 - accuracy: 0.8950 - val_loss: 1.6746 - val_accuracy: 0.7026\n",
      "Epoch 252/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3110 - accuracy: 0.9111 - val_loss: 1.8499 - val_accuracy: 0.6946\n",
      "Epoch 253/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3359 - accuracy: 0.9003 - val_loss: 1.7328 - val_accuracy: 0.7070\n",
      "Epoch 254/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3376 - accuracy: 0.9034 - val_loss: 1.6993 - val_accuracy: 0.6990\n",
      "Epoch 255/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3287 - accuracy: 0.9064 - val_loss: 1.7322 - val_accuracy: 0.7100\n",
      "Epoch 256/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3489 - accuracy: 0.9001 - val_loss: 1.7265 - val_accuracy: 0.7026\n",
      "Epoch 257/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3238 - accuracy: 0.9054 - val_loss: 1.8005 - val_accuracy: 0.6931\n",
      "Epoch 258/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3234 - accuracy: 0.9049 - val_loss: 1.7355 - val_accuracy: 0.7019\n",
      "Epoch 259/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3243 - accuracy: 0.9071 - val_loss: 1.7291 - val_accuracy: 0.7004\n",
      "Epoch 260/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3271 - accuracy: 0.9016 - val_loss: 1.7228 - val_accuracy: 0.7026\n",
      "Epoch 261/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3083 - accuracy: 0.9102 - val_loss: 1.7963 - val_accuracy: 0.6938\n",
      "Epoch 262/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2970 - accuracy: 0.9135 - val_loss: 1.7627 - val_accuracy: 0.7026\n",
      "Epoch 263/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2968 - accuracy: 0.9131 - val_loss: 1.7316 - val_accuracy: 0.7026\n",
      "Epoch 264/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3219 - accuracy: 0.9030 - val_loss: 1.8022 - val_accuracy: 0.7041\n",
      "Epoch 265/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.2871 - accuracy: 0.9163 - val_loss: 1.8602 - val_accuracy: 0.6924\n",
      "Epoch 266/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3005 - accuracy: 0.9139 - val_loss: 1.8886 - val_accuracy: 0.6938\n",
      "Epoch 267/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3053 - accuracy: 0.9108 - val_loss: 1.7689 - val_accuracy: 0.7063\n",
      "Epoch 268/500\n",
      "341/340 [==============================] - 77s 227ms/step - loss: 0.2828 - accuracy: 0.9192 - val_loss: 1.7717 - val_accuracy: 0.7056\n",
      "Epoch 269/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2841 - accuracy: 0.9188 - val_loss: 1.7600 - val_accuracy: 0.6990\n",
      "Epoch 270/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2919 - accuracy: 0.9119 - val_loss: 1.8542 - val_accuracy: 0.6982\n",
      "Epoch 271/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.3147 - accuracy: 0.9109 - val_loss: 1.7436 - val_accuracy: 0.7129\n",
      "Epoch 272/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2901 - accuracy: 0.9137 - val_loss: 1.7647 - val_accuracy: 0.7026\n",
      "Epoch 273/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2978 - accuracy: 0.9131 - val_loss: 1.7377 - val_accuracy: 0.7056\n",
      "Epoch 274/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2675 - accuracy: 0.9236 - val_loss: 1.7695 - val_accuracy: 0.7078\n",
      "Epoch 275/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2719 - accuracy: 0.9187 - val_loss: 1.7576 - val_accuracy: 0.7056\n",
      "Epoch 276/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2687 - accuracy: 0.9187 - val_loss: 1.8157 - val_accuracy: 0.6953\n",
      "Epoch 277/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2806 - accuracy: 0.9221 - val_loss: 1.7698 - val_accuracy: 0.7041\n",
      "Epoch 278/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2610 - accuracy: 0.9227 - val_loss: 1.8083 - val_accuracy: 0.7026\n",
      "Epoch 279/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2691 - accuracy: 0.9194 - val_loss: 1.7802 - val_accuracy: 0.7122\n",
      "Epoch 280/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2694 - accuracy: 0.9216 - val_loss: 1.8608 - val_accuracy: 0.7041\n",
      "Epoch 281/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2562 - accuracy: 0.9280 - val_loss: 1.8317 - val_accuracy: 0.7078\n",
      "Epoch 282/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2443 - accuracy: 0.9254 - val_loss: 1.7583 - val_accuracy: 0.7085\n",
      "Epoch 283/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2646 - accuracy: 0.9174 - val_loss: 1.7666 - val_accuracy: 0.7100\n",
      "Epoch 284/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.2478 - accuracy: 0.9266 - val_loss: 1.7915 - val_accuracy: 0.7026\n",
      "Epoch 285/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2477 - accuracy: 0.9275 - val_loss: 1.8133 - val_accuracy: 0.7085\n",
      "Epoch 286/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2428 - accuracy: 0.9288 - val_loss: 1.6994 - val_accuracy: 0.7107\n",
      "Epoch 287/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2325 - accuracy: 0.9311 - val_loss: 1.7985 - val_accuracy: 0.7129\n",
      "Epoch 288/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2615 - accuracy: 0.9245 - val_loss: 1.7168 - val_accuracy: 0.7093\n",
      "Epoch 289/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.2398 - accuracy: 0.9275 - val_loss: 1.7741 - val_accuracy: 0.7070\n",
      "Epoch 290/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2534 - accuracy: 0.9275 - val_loss: 1.8218 - val_accuracy: 0.7056\n",
      "Epoch 291/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2465 - accuracy: 0.9266 - val_loss: 1.7173 - val_accuracy: 0.7151\n",
      "Epoch 292/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2262 - accuracy: 0.9324 - val_loss: 1.8058 - val_accuracy: 0.7166\n",
      "Epoch 293/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.2248 - accuracy: 0.9335 - val_loss: 1.7593 - val_accuracy: 0.7129\n",
      "Epoch 294/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2375 - accuracy: 0.9310 - val_loss: 1.8337 - val_accuracy: 0.7085\n",
      "Epoch 295/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2194 - accuracy: 0.9346 - val_loss: 1.8518 - val_accuracy: 0.7137\n",
      "Epoch 296/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.2397 - accuracy: 0.9262 - val_loss: 1.8727 - val_accuracy: 0.7078\n",
      "Epoch 297/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.2571 - accuracy: 0.9249 - val_loss: 1.7654 - val_accuracy: 0.7041\n",
      "Epoch 298/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.2295 - accuracy: 0.9324 - val_loss: 1.8351 - val_accuracy: 0.7122\n",
      "Epoch 299/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2243 - accuracy: 0.9322 - val_loss: 1.8548 - val_accuracy: 0.7122\n",
      "Epoch 300/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.2301 - accuracy: 0.9306 - val_loss: 1.8678 - val_accuracy: 0.7041\n",
      "Epoch 301/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2274 - accuracy: 0.9381 - val_loss: 1.7821 - val_accuracy: 0.7085\n",
      "Epoch 302/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2230 - accuracy: 0.9365 - val_loss: 1.7511 - val_accuracy: 0.7247\n",
      "Epoch 303/500\n",
      "341/340 [==============================] - 76s 224ms/step - loss: 0.2150 - accuracy: 0.9355 - val_loss: 1.7518 - val_accuracy: 0.7188\n",
      "Epoch 304/500\n",
      "341/340 [==============================] - 77s 224ms/step - loss: 0.2102 - accuracy: 0.9368 - val_loss: 1.8132 - val_accuracy: 0.7041\n",
      "Epoch 305/500\n",
      "341/340 [==============================] - 76s 224ms/step - loss: 0.2187 - accuracy: 0.9376 - val_loss: 1.7860 - val_accuracy: 0.7085\n",
      "Epoch 306/500\n",
      "341/340 [==============================] - 76s 224ms/step - loss: 0.2421 - accuracy: 0.9271 - val_loss: 1.7768 - val_accuracy: 0.7078\n",
      "Epoch 307/500\n",
      "341/340 [==============================] - 77s 224ms/step - loss: 0.2166 - accuracy: 0.9367 - val_loss: 1.7702 - val_accuracy: 0.7041\n",
      "Epoch 308/500\n",
      "341/340 [==============================] - 76s 224ms/step - loss: 0.2219 - accuracy: 0.9319 - val_loss: 1.7837 - val_accuracy: 0.7034\n",
      "Epoch 309/500\n",
      "341/340 [==============================] - 76s 224ms/step - loss: 0.2105 - accuracy: 0.9387 - val_loss: 1.7909 - val_accuracy: 0.7093\n",
      "Epoch 310/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 0.2176 - accuracy: 0.9378 - val_loss: 1.8349 - val_accuracy: 0.7151\n",
      "Epoch 311/500\n",
      "341/340 [==============================] - 78s 227ms/step - loss: 0.2115 - accuracy: 0.9422 - val_loss: 1.8658 - val_accuracy: 0.7063\n",
      "Epoch 312/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.1905 - accuracy: 0.9438 - val_loss: 1.8280 - val_accuracy: 0.7034\n",
      "Epoch 313/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.2057 - accuracy: 0.9368 - val_loss: 1.8016 - val_accuracy: 0.7078\n",
      "Epoch 314/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.2076 - accuracy: 0.9372 - val_loss: 1.7669 - val_accuracy: 0.7100\n",
      "Epoch 315/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.2039 - accuracy: 0.9412 - val_loss: 1.8740 - val_accuracy: 0.7115\n",
      "Epoch 316/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.1847 - accuracy: 0.9449 - val_loss: 1.7599 - val_accuracy: 0.7247\n",
      "Epoch 317/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.1953 - accuracy: 0.9403 - val_loss: 1.9081 - val_accuracy: 0.7041\n",
      "Epoch 318/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.2081 - accuracy: 0.9379 - val_loss: 1.8070 - val_accuracy: 0.7137\n",
      "Epoch 319/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.1935 - accuracy: 0.9418 - val_loss: 1.7878 - val_accuracy: 0.7063\n",
      "Epoch 320/500\n",
      "341/340 [==============================] - 77s 226ms/step - loss: 0.1978 - accuracy: 0.9427 - val_loss: 1.7440 - val_accuracy: 0.7181\n",
      "Epoch 321/500\n",
      "341/340 [==============================] - 78s 228ms/step - loss: 0.1905 - accuracy: 0.9464 - val_loss: 1.8220 - val_accuracy: 0.7085\n",
      "Epoch 322/500\n",
      "341/340 [==============================] - 76s 223ms/step - loss: 0.1925 - accuracy: 0.9423 - val_loss: 1.7926 - val_accuracy: 0.7144\n",
      "Epoch 323/500\n",
      "341/340 [==============================] - 76s 223ms/step - loss: 0.1985 - accuracy: 0.9425 - val_loss: 1.8555 - val_accuracy: 0.7093\n",
      "Epoch 324/500\n",
      "341/340 [==============================] - 76s 223ms/step - loss: 0.1858 - accuracy: 0.9451 - val_loss: 1.8875 - val_accuracy: 0.7041\n",
      "Epoch 325/500\n",
      "341/340 [==============================] - 76s 223ms/step - loss: 0.1806 - accuracy: 0.9475 - val_loss: 1.8855 - val_accuracy: 0.7056\n",
      "Epoch 326/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.1902 - accuracy: 0.9427 - val_loss: 1.8627 - val_accuracy: 0.7173\n",
      "Epoch 327/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.1909 - accuracy: 0.9431 - val_loss: 1.8293 - val_accuracy: 0.7239\n",
      "Epoch 328/500\n",
      "341/340 [==============================] - 77s 224ms/step - loss: 0.1819 - accuracy: 0.9482 - val_loss: 1.7522 - val_accuracy: 0.7151\n",
      "Epoch 329/500\n",
      "341/340 [==============================] - 76s 224ms/step - loss: 0.1990 - accuracy: 0.9422 - val_loss: 1.8001 - val_accuracy: 0.7115\n",
      "Epoch 330/500\n",
      "341/340 [==============================] - 77s 224ms/step - loss: 0.1882 - accuracy: 0.9438 - val_loss: 1.8583 - val_accuracy: 0.7063\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/340 [==============================] - 77s 224ms/step - loss: 0.1853 - accuracy: 0.9438 - val_loss: 1.8491 - val_accuracy: 0.7144\n",
      "Epoch 332/500\n",
      "341/340 [==============================] - 77s 224ms/step - loss: 0.1849 - accuracy: 0.9469 - val_loss: 1.7663 - val_accuracy: 0.7254\n",
      "Epoch 333/500\n",
      "341/340 [==============================] - 77s 224ms/step - loss: 0.1706 - accuracy: 0.9506 - val_loss: 1.7946 - val_accuracy: 0.7159\n",
      "Epoch 334/500\n",
      "341/340 [==============================] - 76s 224ms/step - loss: 0.1747 - accuracy: 0.9513 - val_loss: 1.8066 - val_accuracy: 0.7247\n",
      "Epoch 335/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.1763 - accuracy: 0.9512 - val_loss: 1.7938 - val_accuracy: 0.7232\n",
      "Epoch 336/500\n",
      "341/340 [==============================] - 77s 224ms/step - loss: 0.1644 - accuracy: 0.9501 - val_loss: 1.8157 - val_accuracy: 0.7188\n",
      "Epoch 337/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.1814 - accuracy: 0.9462 - val_loss: 1.7816 - val_accuracy: 0.7203\n",
      "Epoch 338/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.1712 - accuracy: 0.9491 - val_loss: 1.8801 - val_accuracy: 0.7166\n",
      "Epoch 339/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.1642 - accuracy: 0.9557 - val_loss: 1.8308 - val_accuracy: 0.7100\n",
      "Epoch 340/500\n",
      "341/340 [==============================] - 77s 225ms/step - loss: 0.1571 - accuracy: 0.9534 - val_loss: 1.8754 - val_accuracy: 0.7144\n",
      "Epoch 341/500\n",
      "163/340 [=============>................] - ETA: 37s - loss: 0.1592 - accuracy: 0.9502"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-9422a8a8c13a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m history = model.fit_generator(img_gen.flow(train_images*255, train_labels, batch_size = 16),\n\u001b[1;32m----> 4\u001b[1;33m                                       steps_per_epoch = len(train_images)/16, validation_data = (test_images,test_labels), epochs = 500)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1479\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \"\"\"\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    517\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \"\"\"\n\u001b[0;32m    960\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit_generator(img_gen.flow(train_images*255, train_labels, batch_size = 16),\n",
    "                                      steps_per_epoch = len(train_images)/16, validation_data = (test_images,test_labels), epochs = 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model in 33. after small dataset') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Accuracy: {:.2f} %, Val Accuracy {:.2f} %'.format(100*history.history['accuracy'][-1],\n",
    "#                                                          100*history.history['val_accuracy'][-1]))\n",
    "# print('Loss: {:.4f} , Val Loss {:.4f}'.format(history.history['loss'][-1], history.history['val_loss'][-1]))\n",
    "# print('Precision: {:.4f} , Val Precision {:.4f}'.format(history.history['precision'][-1], history.history['val_precision'][-1]))\n",
    "# print('Recall: {:.4f}, Val Recall {:.4f}'.format(history.history['recall'][-1], history.history['val_recall'][-1]))\n",
    "# print('AUC: {:.4f}, Val AUC {:.4f}'.format(history.history['auc'][-1], history.history['val_auc'][-1]))\n",
    "# print()\n",
    "# print('TP: {:.0f}'.format(history.history['tp'][-1]))\n",
    "# print('FP: {:.0f}'.format(history.history['fp'][-1]))\n",
    "# print('TN: {:.0f}'.format(history.history['tn'][-1]))\n",
    "# print('FN: {:.0f}'.format(history.history['fn'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Precision')\n",
    "plt.plot(history.history['precision'], label='precision')\n",
    "plt.plot(history.history['val_precision'], label = 'val_precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "# plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Recall')\n",
    "plt.plot(history.history['recall'], label='recall')\n",
    "plt.plot(history.history['val_recall'], label = 'val_recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "# plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('AUC')\n",
    "plt.plot(history.history['auc'], label='auc')\n",
    "plt.plot(history.history['val_auc'], label = 'val_auc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "# plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存/取模型\n",
    "# model.save('/model in 6.CNN with more databy pad and flip') \n",
    "# loaded_model = tf.keras.models.load_model('/tmp/model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot  # plot 可以視為畫布\n",
    "import math\n",
    "\n",
    "def show_feature_label_prediction(features, labels, predictions, indexList):\n",
    "    num = len(indexList)\n",
    "\n",
    "    plot.gcf().set_size_inches( 2*5, (2+0.4)*math.ceil(num/5) )\n",
    "\n",
    "    loc = 0\n",
    "    for i in indexList :\n",
    "        loc += 1\n",
    "        subp = plot.subplot( math.ceil(num/5), 5, loc )\n",
    "        subp.imshow( features[i], cmap='binary' )\n",
    "\n",
    "        if( len(predictions) > 0 ) :\n",
    "            title = 'prediction = ' + str(predictions[i])\n",
    "            title += (' (o)' if predictions[i]==labels[i] else ' (x)') # predict result\n",
    "            title += '\\nlabel = ' + str(labels[i])\n",
    "        else :\n",
    "            title = 'label = ' + str(labels[i])\n",
    "\n",
    "        subp.set_title( title, fontsize=12 )\n",
    "        subp.set_xticks( [] )\n",
    "        subp.set_yticks( [] )\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_misprediction(features, labels, predictions, indexList):\n",
    "    num = len(indexList)\n",
    "\n",
    "    plot.gcf().set_size_inches( 2*5, (2+0.4)*math.ceil(num/5) )\n",
    "\n",
    "    loc = 0\n",
    "    for i in indexList :\n",
    "\n",
    "        if(len(predictions)> 0) & (predictions[i]!=labels[i]):\n",
    "            loc += 1\n",
    "            subp = plot.subplot( math.ceil(num/5), 5, loc )\n",
    "            subp.imshow(features[i], cmap='binary' )\n",
    "            title = str(labels[i])\n",
    "            title += (' (o)' if predictions[i]==labels[i] else ' (x)') # predict result\n",
    "            subp.set_title( title, fontsize=12 )\n",
    "        else :\n",
    "            continue\n",
    "#             title = 'label = ' + str(labels[i])\n",
    "\n",
    "        \n",
    "        subp.set_xticks( [] )\n",
    "        subp.set_yticks( [] )\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = []\n",
    "prediction = model.predict_classes(test_images)\n",
    "for i in range(len(test_labels_org)):\n",
    "    if prediction[i]!=test_labels_org[i]:\n",
    "        re.append(test_labels_org[i])\n",
    "# sorted(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(test_images)\n",
    "show_feature_label_prediction(test_images, test_labels_org, prediction, range(0, len(test_labels_org)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(test_images)\n",
    "show_misprediction(test_images, test_labels_org, prediction, range(0, len(test_labels_org)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'name': np.unique(list(name_list))})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
