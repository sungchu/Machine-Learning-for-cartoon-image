{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import build_opener\n",
    "from urllib.request import install_opener\n",
    "import os\n",
    "import pathlib\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers, metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "# for physical_device in physical_devices: \n",
    "#     tf.config.experimental.set_memory_growth(physical_device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count how many images in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name_list = ['001_Bulbasaur', '002_Ivysaur', '003_Venusaur', '004_Charmander', '005_Charmeleon',\n",
    " '006_Charizard', '007_Squirtle', '008_Wartortle', '009_Blastoise', '010_Caterpie', '011_Metapod',\n",
    " '012_Butterfree', '013_Weedle', '014_Kakuna', '015_Beedrill', '016_Pidgey', '017_Pidgeotto', '018_Pidgeot',\n",
    " '019_Rattata', '020_Raticate', '021_Spearow', '022_Fearow', '023_Ekans', '024_Arbok', '025_Pikachu', '026_Raichu',\n",
    " '027_Sandshrew', '028_Sandslash', '029_Nidoran♀', '030_Nidorina', '031_Nidoqueen', '032_Nidoran♂', '033_Nidorino',\n",
    " '034_Nidoking', '035_Clefairy', '036_Clefable', '037_Vulpix', '038_Ninetales', '039_Jigglypuff', '040_Wigglytuff',\n",
    " '041_Zubat', '042_Golbat', '043_Oddish', '044_Gloom', '045_Vileplume', '046_Paras', '047_Parasect', '048_Venonat',\n",
    " '049_Venomoth', '050_Diglett', '051_Dugtrio', '052_Meowth', '053_Persian', '054_Psyduck', '055_Golduck', '056_Mankey',\n",
    " '057_Primeape', '058_Growlithe', '059_Arcanine', '060_Poliwag', '061_Poliwhirl', '062_Poliwrath', '063_Abra',\n",
    " '064_Kadabra', '065_Alakazam', '066_Machop', '067_Machoke', '068_Machamp', '069_Bellsprout', '070_Weepinbell',\n",
    " '071_Victreebel', '072_Tentacool', '073_Tentacruel', '074_Geodude', '075_Graveler', '076_Golem', '077_Ponyta',\n",
    " '078_Rapidash', '079_Slowpoke', '080_Slowbro', '081_Magnemite', '082_Magneton', \"083_Farfetch'd\", '084_Doduo',\n",
    " '085_Dodrio', '086_Seel', '087_Dewgong', '088_Grimer', '089_Muk', '090_Shellder', '091_Cloyster', '092_Gastly',\n",
    " '093_Haunter', '094_Gengar', '095_Onix', '096_Drowzee', '097_Hypno', '098_Krabby', '099_Kingler', '100_Voltorb',\n",
    " '101_Electrode', '102_Exeggcute', '103_Exeggutor', '104_Cubone', '105_Marowak', '106_Hitmonlee', '107_Hitmonchan',\n",
    " '108_Lickitung', '109_Koffing', '110_Weezing', '111_Rhyhorn', '112_Rhydon', '113_Chansey', '114_Tangela',\n",
    " '115_Kangaskhan', '116_Horsea', '117_Seadra', '118_Goldeen', '119_Seaking', '120_Staryu', '121_Starmie',\n",
    " '122_Mr. Mime', '123_Scyther', '124_Jynx', '125_Electabuzz', '126_Magmar', '127_Pinsir', '128_Tauros',\n",
    " '129_Magikarp', '130_Gyarados', '131_Lapras', '132_Ditto', '133_Eevee', '134_Vaporeon', '135_Jolteon',\n",
    " '136_Flareon', '137_Porygon', '138_Omanyte', '139_Omastar', '140_Kabuto', '141_Kabutops', '142_Aerodactyl',\n",
    " '143_Snorlax', '144_Articuno', '145_Zapdos', '146_Moltres', '147_Dratini', '148_Dragonair', '149_Dragonite',\n",
    " '150_Mewtwo', '151_Mew', '152_Chikorita', '153_Bayleef', '154_Meganium', '155_Cyndaquil', '156_Quilava', '157_Typhlosion',\n",
    " '158_Totodile', '159_Croconaw', '160_Feraligatr', '161_Sentret', '162_Furret', '163_Hoothoot', '164_Noctowl',\n",
    " '165_Ledyba', '166_Ledian', '167_Spinarak', '168_Ariados', '169_Crobat', '170_Chinchou', '171_Lanturn', '172_Pichu',\n",
    " '173_Cleffa', '174_Igglybuff', '175_Togepi', '176_Togetic', '177_Natu', '178_Xatu', '179_Mareep', '180_Flaaffy',\n",
    " '181_Ampharos', '182_Bellossom', '183_Marill', '184_Azumarill', '185_Sudowoodo', '186_Politoed', '187_Hoppip',\n",
    " '188_Skiploom', '189_Jumpluff', '190_Aipom', '191_Sunkern', '192_Sunflora', '193_Yanma', '194_Wooper', '195_Quagsire',\n",
    " '196_Espeon', '197_Umbreon', '198_Murkrow', '199_Slowking', '200_Misdreavus', '201_Unown', '202_Wobbuffet', '203_Girafarig',\n",
    " '204_Pineco', '205_Forretress', '206_Dunsparce', '207_Gligar', '208_Steelix', '209_Snubbull', '210_Granbull',\n",
    " '211_Qwilfish', '212_Scizor', '213_Shuckle', '214_Heracross', '215_Sneasel', '216_Teddiursa', '217_Ursaring',\n",
    " '218_Slugma', '219_Magcargo', '220_Swinub', '221_Piloswine', '222_Corsola', '223_Remoraid', '224_Octillery',\n",
    " '225_Delibird', '226_Mantine', '227_Skarmory', '228_Houndour', '229_Houndoom', '230_Kingdra', '231_Phanpy',\n",
    " '232_Donphan', '233_Porygon2', '234_Stantler', '235_Smeargle', '236_Tyrogue', '237_Hitmontop', '238_Smoochum',\n",
    " '239_Elekid', '240_Magby', '241_Miltank', '242_Blissey', '243_Raikou', '244_Entei', '245_Suicune', '246_Larvitar',\n",
    " '247_Pupitar', '248_Tyranitar', '249_Lugia', '250_Ho-Oh', '251_Celebi', '252_Treecko', '253_Grovyle', '254_Sceptile',\n",
    " '255_Torchic', '256_Combusken', '257_Blaziken', '258_Mudkip', '259_Marshtomp', '260_Swampert', '261_Poochyena',\n",
    " '262_Mightyena', '263_Zigzagoon', '264_Linoone', '265_Wurmple', '266_Silcoon', '267_Beautifly', '268_Cascoon',\n",
    " '269_Dustox', '270_Lotad', '271_Lombre', '272_Ludicolo', '273_Seedot', '274_Nuzleaf', '275_Shiftry', '276_Taillow',\n",
    " '277_Swellow', '278_Wingull', '279_Pelipper', '280_Ralts', '281_Kirlia', '282_Gardevoir', '283_Surskit', '284_Masquerain',\n",
    " '285_Shroomish', '286_Breloom', '287_Slakoth', '288_Vigoroth', '289_Slaking', '290_Nincada', '291_Ninjask',\n",
    " '292_Shedinja', '293_Whismur', '294_Loudred', '295_Exploud', '296_Makuhita', '297_Hariyama', '298_Azurill',\n",
    " '299_Nosepass', '300_Skitty', '301_Delcatty', '302_Sableye', '303_Mawile', '304_Aron', '305_Lairon', '306_Aggron',\n",
    " '307_Meditite', '308_Medicham', '309_Electrike', '310_Manectric', '311_Plusle', '312_Minun', '313_Volbeat',\n",
    " '314_Illumise', '315_Roselia', '316_Gulpin', '317_Swalot', '318_Carvanha', '319_Sharpedo', '320_Wailmer',\n",
    " '321_Wailord', '322_Numel', '323_Camerupt', '324_Torkoal', '325_Spoink', '326_Grumpig', '327_Spinda',\n",
    " '328_Trapinch', '329_Vibrava', '330_Flygon', '331_Cacnea', '332_Cacturne', '333_Swablu', '334_Altaria', '335_Zangoose',\n",
    " '336_Seviper', '337_Lunatone', '338_Solrock', '339_Barboach', '340_Whiscash', '341_Corphish', '342_Crawdaunt',\n",
    " '343_Baltoy', '344_Claydol', '345_Lileep', '346_Cradily', '347_Anorith', '348_Armaldo', '349_Feebas', '350_Milotic',\n",
    " '351_Castform', '352_Kecleon', '353_Shuppet', '354_Banette', '355_Duskull', '356_Dusclops', '357_Tropius', '358_Chimecho',\n",
    " '359_Absol', '360_Wynaut', '361_Snorunt', '362_Glalie', '363_Spheal', '364_Sealeo', '365_Walrein', '366_Clamperl',\n",
    " '367_Huntail', '368_Gorebyss', '369_Relicanth', '370_Luvdisc', '371_Bagon', '372_Shelgon', '373_Salamence', '374_Beldum',\n",
    " '375_Metang', '376_Metagross', '377_Regirock', '378_Regice', '379_Registeel', '380_Latias', '381_Latios', '382_Kyogre',\n",
    " '383_Groudon', '384_Rayquaza', '385_Jirachi', '386_Deoxys', '387_Turtwig', '388_Grotle', '389_Torterra', '390_Chimchar',\n",
    " '391_Monferno', '392_Infernape', '393_Piplup', '394_Prinplup', '395_Empoleon', '396_Starly', '397_Staravia', '398_Staraptor',\n",
    " '399_Bidoof', '400_Bibarel', '401_Kricketot', '402_Kricketune', '403_Shinx', '404_Luxio', '405_Luxray',\n",
    " '406_Budew', '407_Roserade', '408_Cranidos', '409_Rampardos', '410_Shieldon', '411_Bastiodon', '412_Burmy', '413_Wormadam',\n",
    " '414_Mothim', '415_Combee', '416_Vespiquen', '417_Pachirisu', '418_Buizel', '419_Floatzel', '420_Cherubi', '421_Cherrim',\n",
    " '422_Shellos', '423_Gastrodon', '424_Ambipom', '425_Drifloon', '426_Drifblim', '427_Buneary', '428_Lopunny',\n",
    " '429_Mismagius', '430_Honchkrow', '431_Glameow', '432_Purugly', '433_Chingling', '434_Stunky', '435_Skuntank',\n",
    " '436_Bronzor', '437_Bronzong', '438_Bonsly', '439_Mime Jr.', '440_Happiny', '441_Chatot', '442_Spiritomb', '443_Gible',\n",
    " '444_Gabite', '445_Garchomp', '446_Munchlax', '447_Riolu', '448_Lucario', '449_Hippopotas', '450_Hippowdon', '451_Skorupi',\n",
    " '452_Drapion', '453_Croagunk', '454_Toxicroak', '455_Carnivine', '456_Finneon', '457_Lumineon', '458_Mantyke',\n",
    " '459_Snover', '460_Abomasnow', '461_Weavile', '462_Magnezone', '463_Lickilicky', '464_Rhyperior', '465_Tangrowth',\n",
    " '466_Electivire', '467_Magmortar', '468_Togekiss', '469_Yanmega', '470_Leafeon', '471_Glaceon', '472_Gliscor', '473_Mamoswine',\n",
    " '474_Porygon-Z', '475_Gallade', '476_Probopass', '477_Dusknoir', '478_Froslass', '479_Rotom', '480_Uxie', '481_Mesprit',\n",
    " '482_Azelf', '483_Dialga', '484_Palkia', '485_Heatran', '486_Regigigas', '487_Giratina', '488_Cresselia', '489_Phione',\n",
    " '490_Manaphy', '491_Darkrai', '492_Shaymin', '493_Arceus', '494_Victini', '495_Snivy', '496_Servine', '497_Serperior', '498_Tepig',\n",
    " '499_Pignite', '500_Emboar', '501_Oshawott', '502_Dewott', '503_Samurott', '504_Patrat', '505_Watchog',\n",
    " '506_Lillipup', '507_Herdier', '508_Stoutland', '509_Purrloin', '510_Liepard', '511_Pansage', '512_Simisage',\n",
    " '513_Pansear', '514_Simisear', '515_Panpour', '516_Simipour', '517_Munna', '518_Musharna', '519_Pidove', '520_Tranquill',\n",
    " '521_Unfezant', '522_Blitzle', '523_Zebstrika', '524_Roggenrola', '525_Boldore', '526_Gigalith', '527_Woobat',\n",
    " '528_Swoobat', '529_Drilbur', '530_Excadrill', '531_Audino', '532_Timburr', '533_Gurdurr', '534_Conkeldurr',\n",
    " '535_Tympole', '536_Palpitoad', '537_Seismitoad', '538_Throh', '539_Sawk', '540_Sewaddle', '541_Swadloon', '542_Leavanny',\n",
    " '543_Venipede', '544_Whirlipede', '545_Scolipede', '546_Cottonee', '547_Whimsicott', '548_Petilil', '549_Lilligant', \n",
    " '550_Basculin', '551_Sandile', '552_Krokorok', '553_Krookodile', '554_Darumaka', '555_Darmanitan', '556_Maractus',\n",
    " '557_Dwebble', '558_Crustle', '559_Scraggy', '560_Scrafty', '561_Sigilyph', '562_Yamask', '563_Cofagrigus',\n",
    " '564_Tirtouga', '565_Carracosta', '566_Archen', '567_Archeops', '568_Trubbish', '569_Garbodor', '570_Zorua', '571_Zoroark',\n",
    " '572_Minccino', '573_Cinccino', '574_Gothita', '575_Gothorita', '576_Gothitelle', '577_Solosis',\n",
    " '578_Duosion', '579_Reuniclus', '580_Ducklett', '581_Swanna', '582_Vanillite', '583_Vanillish', '584_Vanilluxe',\n",
    " '585_Deerling', '586_Sawsbuck', '587_Emolga', '588_Karrablast', '589_Escavalier', '590_Foongus', '591_Amoonguss',\n",
    " '592_Frillish', '593_Jellicent', '594_Alomomola', '595_Joltik', '596_Galvantula', '597_Ferroseed', '598_Ferrothorn',\n",
    " '599_Klink', '600_Klang', '601_Klinklang', '602_Tynamo', '603_Eelektrik', '604_Eelektross', '605_Elgyem',\n",
    " '606_Beheeyem', '607_Litwick', '608_Lampent', '609_Chandelure', '610_Axew', '611_Fraxure', '612_Haxorus', '613_Cubchoo',\n",
    " '614_Beartic', '615_Cryogonal', '616_Shelmet', '617_Accelgor', '618_Stunfisk', '619_Mienfoo', '620_Mienshao',\n",
    " '621_Druddigon', '622_Golett', '623_Golurk', '624_Pawniard', '625_Bisharp', '626_Bouffalant', '627_Rufflet',\n",
    " '628_Braviary', '629_Vullaby', '630_Mandibuzz', '631_Heatmor', '632_Durant', '633_Deino', '634_Zweilous',\n",
    " '635_Hydreigon', '636_Larvesta', '637_Volcarona', '638_Cobalion', '639_Terrakion', '640_Virizion', '641_Tornadus',\n",
    " '642_Thundurus', '643_Reshiram', '644_Zekrom', '645_Landorus', '646_Kyurem', '647_Keldeo', '648_Meloetta', '649_Genesect',\n",
    " '650_Chespin', '651_Quilladin', '652_Chesnaught', '653_Fennekin', '654_Braixen', '655_Delphox', '656_Froakie',\n",
    " '657_Frogadier', '658_Greninja', '659_Bunnelby', '660_Diggersby', '661_Fletchling', '662_Fletchinder',\n",
    " '663_Talonflame', '664_Scatterbug', '665_Spewpa', '666_Vivillon', '667_Litleo', '668_Pyroar', '669_Flabébé',\n",
    " '670_Floette', '671_Florges', '672_Skiddo', '673_Gogoat', '674_Pancham', '675_Pangoro', '676_Furfrou', '677_Espurr',\n",
    " '678_Meowstic', '679_Honedge', '680_Doublade', '681_Aegislash', '682_Spritzee', '683_Aromatisse', '684_Swirlix',\n",
    " '685_Slurpuff', '686_Inkay', '687_Malamar', '688_Binacle', '689_Barbaracle', '690_Skrelp', '691_Dragalge', '692_Clauncher',\n",
    " '693_Clawitzer', '694_Helioptile', '695_Heliolisk', '696_Tyrunt', '697_Tyrantrum', '698_Amaura', '699_Aurorus', \n",
    " '700_Sylveon', '701_Hawlucha', '702_Dedenne', '703_Carbink', '704_Goomy', '705_Sliggoo', '706_Goodra', '707_Klefki',\n",
    " '708_Phantump', '709_Trevenant', '710_Pumpkaboo', '711_Gourgeist', '712_Bergmite', '713_Avalugg',\n",
    " '714_Noibat', '715_Noivern', '716_Xerneas', '717_Yveltal', '718_Zygarde', '719_Diancie', '720_Hoopa', '721_Volcanion',\n",
    " '722_Rowlet', '723_Dartrix', '724_Decidueye', '725_Litten', '726_Torracat', '727_Incineroar', '728_Popplio',\n",
    " '729_Brionne', '730_Primarina', '731_Pikipek', '732_Trumbeak', '733_Toucannon', '734_Yungoos', '735_Gumshoos',\n",
    " '736_Grubbin', '737_Charjabug', '738_Vikavolt', '739_Crabrawler', '740_Crabominable', '741_Oricorio', '742_Cutiefly',\n",
    " '743_Ribombee', '744_Rockruff', '745_Lycanroc', '746_Wishiwashi', '747_Mareanie', '748_Toxapex', '749_Mudbray',\n",
    " '750_Mudsdale', '751_Dewpider', '752_Araquanid', '753_Fomantis', '754_Lurantis', '755_Morelull', '756_Shiinotic',\n",
    " '757_Salandit', '758_Salazzle', '759_Stufful', '760_Bewear', '761_Bounsweet', '762_Steenee', '763_Tsareena',\n",
    " '764_Comfey', '765_Oranguru', '766_Passimian', '767_Wimpod', '768_Golisopod', '769_Sandygast', '770_Palossand',\n",
    " '771_Pyukumuku', '772_Type_Null', '773_Silvally', '774_Minior', '775_Komala', '776_Turtonator', '777_Togedemaru',\n",
    " '778_Mimikyu', '779_Bruxish', '780_Drampa', '781_Dhelmise', '782_Jangmo-o', '783_Hakamo-o', '784_Kommo-o',\n",
    " '785_Tapu Koko', '786_Tapu Lele', '787_Tapu Bulu', '788_Tapu Fini', '789_Cosmog', '790_Cosmoem', '791_Solgaleo',\n",
    " '792_Lunala', '793_Nihilego', '794_Buzzwole', '795_Pheromosa', '796_Xurkitree', '797_Celesteela', '798_Kartana',\n",
    " '799_Guzzlord', '800_Necrozma', '801_Magearna', '802_Marshadow', '803_Poipole', '804_Naganadel', '805_Stakataka',\n",
    " '806_Blacephalon', '807_Zeraora', '808_Meltan', '809_Melmetal', '810_Grookey', '811_Thwackey', '812_Rillaboom',\n",
    " '813_Scorbunny', '814_Raboot', '815_Cinderace', '816_Sobble', '817_Drizzile', '818_Inteleon', '819_Skwovet',\n",
    " '820_Greedent', '821_Rookidee', '822_Corvisquire', '823_Corviknight', '824_Blipbug', '825_Dottler', '826_Orbeetle',\n",
    " '827_Nickit', '828_Thievul', '829_Gossifleur', '830_Eldegoss', '831_Wooloo', '832_Dubwool', '833_Chewtle', '834_Drednaw',\n",
    " '835_Yamper', '836_Boltund', '837_Rolycoly', '838_Carkol', '839_Coalossal', '840_Applin', '841_Flapple', '842_Appletun',\n",
    " '843_Silicobra', '844_Sandaconda', '845_Cramorant', '846_Arrokuda', '847_Barraskewda', '848_Toxel', '849_Toxtricity',\n",
    " '850_Sizzlipede', '851_Centiskorch', '852_Clobbopus', '853_Grapploct', '854_Sinistea', '855_Polteageist',\n",
    " '856_Hatenna', '857_Hattrem', '858_Hatterene', '859_Impidimp', '860_Morgrem', '861_Grimmsnarl', '862_Obstagoon',\n",
    " '863_Perrserker', '864_Cursola', \"865_Sirfetch'd\", '866_Mr. Rime', '867_Runerigus', '868_Milcery', '869_Alcremie',\n",
    " '870_Falinks', '871_Pincurchin', '872_Snom', '873_Frosmoth', '874_Stonjourner', '875_Eiscue', '876_Indeedee',\n",
    " '877_Morpeko', '878_Cufant', '879_Copperajah', '880_Dracozolt', '881_Arctozolt', '882_Dracovish', '883_Arctovish',\n",
    " '884_Duraludon', '885_Dreepy', '886_Drakloak', '887_Dragapult', '888_Zacian', '889_Zamazenta', '890_Eternatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we filter the images which bigger than (128, 128, 3)\n",
      "We have 783 pokemon containing more than 3 images\n"
     ]
    }
   ],
   "source": [
    "# if image smaller than x, then we will not use them\n",
    "# this section shows how many images will left in each pokemon\n",
    "filter_standard = (128, 128, 3)\n",
    "\n",
    "# filter_df = pd.DataFrame(columns = ['pokemon name', 'amount'])\n",
    "count_list = []\n",
    "\n",
    "for name in folder_name_list:\n",
    "    path = './Pokemon Dataset (convert to png files)/{}'.format(name)\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    count = 0\n",
    "    for i in range(len(onlyfiles)):\n",
    "        image = np.asarray(Image.open('./Pokemon Dataset (convert to png files)/{}/{}'.format(name, onlyfiles[i])))\n",
    "        if image.shape > filter_standard:\n",
    "            count += 1\n",
    "    count_list.append(count)\n",
    "\n",
    "print('When we filter the images which bigger than {}'.format(filter_standard))        \n",
    "print('We have {} pokemon containing more than 3 images'.format(len([i for i in count_list if i >= 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pokemon name</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001_Bulbasaur</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_Ivysaur</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003_Venusaur</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004_Charmander</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005_Charmeleon</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886_Drakloak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887_Dragapult</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888_Zacian</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889_Zamazenta</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890_Eternatus</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>890 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pokemon name  amount\n",
       "0     001_Bulbasaur      22\n",
       "1       002_Ivysaur      13\n",
       "2      003_Venusaur      17\n",
       "3    004_Charmander      20\n",
       "4    005_Charmeleon      10\n",
       "..              ...     ...\n",
       "885    886_Drakloak       1\n",
       "886   887_Dragapult       1\n",
       "887      888_Zacian       2\n",
       "888   889_Zamazenta       2\n",
       "889   890_Eternatus       3\n",
       "\n",
       "[890 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df = pd.DataFrame({'pokemon name': folder_name_list, 'amount': count_list})\n",
    "filter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dataset we need for building CNN below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "name_list = []\n",
    "classes = 0\n",
    "for name in folder_name_list:\n",
    "    path = './Pokemon Dataset (convert to png files)/{}'.format(name)\n",
    "    if os.path.exists(path):\n",
    "        onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "        for i in range(len(onlyfiles)):\n",
    "            image = np.asarray(Image.open('./Pokemon Dataset (convert to png files)/{}/{}'.format(name, onlyfiles[i])))\n",
    "            # if image size is bigger than the standard and the image amount of that pokemon is more than or equal to 3\n",
    "            if (image.shape >= filter_standard) & (folder_name_list.index(name) not in filter_df[filter_df['amount'] < 3].index):\n",
    "                temp = Image.open('./Pokemon Dataset (convert to png files)/{}/{}'.format(name, onlyfiles[i])).resize((227,227), Image.ANTIALIAS)\n",
    "                x.append(np.asarray(temp))\n",
    "                y.append(classes)\n",
    "                name_list.append(name)\n",
    "        classes += 1\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 782, 782, 782])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_encode = []\n",
    "for i in y:\n",
    "    for j in np.unique(y):\n",
    "        if i == j:\n",
    "            class_encode.append(list(np.unique(y)).index(j))\n",
    "np.array(class_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "train_images, test_images, train_labels, test_labels = train_test_split(x, class_encode, test_size = 0.2, random_state = 42, stratify = class_encode)\n",
    "# # Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "train_labels_org = train_labels\n",
    "test_labels_org = test_labels\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "train_labels = np_utils.to_categorical(train_labels)\n",
    "test_labels = np_utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 (Model 5 from 3.CNN but more epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 56, 56, 48)        3648      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 27, 27, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 128)       55424     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 192)       98496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 192)       147648    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 128)       98432     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6000)              27654000  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6000)              36006000  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              24580096  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 783)               3207951   \n",
      "=================================================================\n",
      "Total params: 91,851,695\n",
      "Trainable params: 91,851,695\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(48,(5,5),strides=(4,4), padding = 'valid', activation='relu', input_shape = (227, 227, 3)))\n",
    "model.add(layers.MaxPool2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3),strides=(1,1), padding = 'same', activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(192,(2,2),strides=(1,1),padding='same',activation='relu'))\n",
    "model.add(layers.Conv2D(192,(2,2),strides=(1,1),padding='same',activation='relu'))\n",
    "model.add(layers.Conv2D(128,(2,2),strides=(1,1),padding='same',activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(6000, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(6000, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(len(np.unique(y)), activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    fill_mode='constant',\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-6eab8de9bda3>:4: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/500\n",
      "296/295 [==============================] - 60s 201ms/step - loss: 6.6427 - accuracy: 0.0074 - val_loss: 6.5622 - val_accuracy: 0.0177\n",
      "Epoch 2/500\n",
      "296/295 [==============================] - 63s 212ms/step - loss: 6.5287 - accuracy: 0.0101 - val_loss: 6.4867 - val_accuracy: 0.0194\n",
      "Epoch 3/500\n",
      "296/295 [==============================] - 65s 220ms/step - loss: 6.4896 - accuracy: 0.0129 - val_loss: 6.4737 - val_accuracy: 0.0118\n",
      "Epoch 4/500\n",
      "296/295 [==============================] - 66s 224ms/step - loss: 6.4674 - accuracy: 0.0110 - val_loss: 6.4634 - val_accuracy: 0.0118\n",
      "Epoch 5/500\n",
      "296/295 [==============================] - 67s 227ms/step - loss: 6.4587 - accuracy: 0.0131 - val_loss: 6.4474 - val_accuracy: 0.0118\n",
      "Epoch 6/500\n",
      "296/295 [==============================] - 67s 226ms/step - loss: 6.4445 - accuracy: 0.0156 - val_loss: 6.4256 - val_accuracy: 0.0228\n",
      "Epoch 7/500\n",
      "296/295 [==============================] - 67s 227ms/step - loss: 6.4120 - accuracy: 0.0230 - val_loss: 6.3802 - val_accuracy: 0.0270\n",
      "Epoch 8/500\n",
      "296/295 [==============================] - 68s 229ms/step - loss: 6.3695 - accuracy: 0.0247 - val_loss: 6.3116 - val_accuracy: 0.0287\n",
      "Epoch 9/500\n",
      "296/295 [==============================] - 68s 228ms/step - loss: 6.3079 - accuracy: 0.0256 - val_loss: 6.2460 - val_accuracy: 0.0279\n",
      "Epoch 10/500\n",
      "296/295 [==============================] - 68s 229ms/step - loss: 6.2447 - accuracy: 0.0266 - val_loss: 6.1833 - val_accuracy: 0.0287\n",
      "Epoch 11/500\n",
      "296/295 [==============================] - 67s 227ms/step - loss: 6.1839 - accuracy: 0.0264 - val_loss: 6.1252 - val_accuracy: 0.0279\n",
      "Epoch 12/500\n",
      "296/295 [==============================] - 68s 228ms/step - loss: 6.1319 - accuracy: 0.0270 - val_loss: 6.0809 - val_accuracy: 0.0296\n",
      "Epoch 13/500\n",
      "296/295 [==============================] - 67s 227ms/step - loss: 6.0814 - accuracy: 0.0279 - val_loss: 6.0329 - val_accuracy: 0.0287\n",
      "Epoch 14/500\n",
      "296/295 [==============================] - 69s 234ms/step - loss: 6.0393 - accuracy: 0.0292 - val_loss: 5.9700 - val_accuracy: 0.0321\n",
      "Epoch 15/500\n",
      "296/295 [==============================] - 68s 229ms/step - loss: 5.9916 - accuracy: 0.0309 - val_loss: 5.9210 - val_accuracy: 0.0346\n",
      "Epoch 16/500\n",
      "296/295 [==============================] - 68s 230ms/step - loss: 5.9488 - accuracy: 0.0296 - val_loss: 5.8810 - val_accuracy: 0.0372\n",
      "Epoch 17/500\n",
      "296/295 [==============================] - 69s 233ms/step - loss: 5.9068 - accuracy: 0.0336 - val_loss: 5.8294 - val_accuracy: 0.0397\n",
      "Epoch 18/500\n",
      "296/295 [==============================] - 69s 232ms/step - loss: 5.8532 - accuracy: 0.0368 - val_loss: 5.7796 - val_accuracy: 0.0405\n",
      "Epoch 19/500\n",
      "296/295 [==============================] - 70s 237ms/step - loss: 5.8166 - accuracy: 0.0372 - val_loss: 5.7229 - val_accuracy: 0.0439\n",
      "Epoch 20/500\n",
      "296/295 [==============================] - 70s 235ms/step - loss: 5.7644 - accuracy: 0.0410 - val_loss: 5.6694 - val_accuracy: 0.0456\n",
      "Epoch 21/500\n",
      "296/295 [==============================] - 69s 234ms/step - loss: 5.7039 - accuracy: 0.0427 - val_loss: 5.6035 - val_accuracy: 0.0549\n",
      "Epoch 22/500\n",
      "296/295 [==============================] - 69s 232ms/step - loss: 5.6498 - accuracy: 0.0437 - val_loss: 5.5426 - val_accuracy: 0.0574\n",
      "Epoch 23/500\n",
      "296/295 [==============================] - 70s 238ms/step - loss: 5.5777 - accuracy: 0.0492 - val_loss: 5.4530 - val_accuracy: 0.0600\n",
      "Epoch 24/500\n",
      "296/295 [==============================] - 69s 233ms/step - loss: 5.5061 - accuracy: 0.0545 - val_loss: 5.3978 - val_accuracy: 0.0785\n",
      "Epoch 25/500\n",
      "296/295 [==============================] - 69s 234ms/step - loss: 5.4291 - accuracy: 0.0581 - val_loss: 5.3161 - val_accuracy: 0.0836\n",
      "Epoch 26/500\n",
      "296/295 [==============================] - 70s 235ms/step - loss: 5.3614 - accuracy: 0.0636 - val_loss: 5.2249 - val_accuracy: 0.0895\n",
      "Epoch 27/500\n",
      "296/295 [==============================] - 70s 237ms/step - loss: 5.2755 - accuracy: 0.0699 - val_loss: 5.1356 - val_accuracy: 0.0971\n",
      "Epoch 28/500\n",
      "296/295 [==============================] - 70s 238ms/step - loss: 5.1855 - accuracy: 0.0735 - val_loss: 5.0563 - val_accuracy: 0.1157\n",
      "Epoch 29/500\n",
      "296/295 [==============================] - 71s 240ms/step - loss: 5.1102 - accuracy: 0.0826 - val_loss: 4.9631 - val_accuracy: 0.1233\n",
      "Epoch 30/500\n",
      "296/295 [==============================] - 70s 237ms/step - loss: 5.0130 - accuracy: 0.0896 - val_loss: 4.8768 - val_accuracy: 0.1166\n",
      "Epoch 31/500\n",
      "296/295 [==============================] - 70s 238ms/step - loss: 4.9293 - accuracy: 0.0900 - val_loss: 4.7772 - val_accuracy: 0.1258\n",
      "Epoch 32/500\n",
      "296/295 [==============================] - 72s 242ms/step - loss: 4.8540 - accuracy: 0.0997 - val_loss: 4.6729 - val_accuracy: 0.1343\n",
      "Epoch 33/500\n",
      "296/295 [==============================] - 72s 242ms/step - loss: 4.7386 - accuracy: 0.1112 - val_loss: 4.5614 - val_accuracy: 0.1512\n",
      "Epoch 34/500\n",
      "296/295 [==============================] - 71s 239ms/step - loss: 4.6600 - accuracy: 0.1156 - val_loss: 4.4973 - val_accuracy: 0.1681\n",
      "Epoch 35/500\n",
      "296/295 [==============================] - 72s 242ms/step - loss: 4.5735 - accuracy: 0.1181 - val_loss: 4.4118 - val_accuracy: 0.1807\n",
      "Epoch 36/500\n",
      "296/295 [==============================] - 72s 244ms/step - loss: 4.4602 - accuracy: 0.1257 - val_loss: 4.3079 - val_accuracy: 0.1883\n",
      "Epoch 37/500\n",
      "296/295 [==============================] - 72s 245ms/step - loss: 4.3584 - accuracy: 0.1386 - val_loss: 4.2453 - val_accuracy: 0.1959\n",
      "Epoch 38/500\n",
      "296/295 [==============================] - 72s 242ms/step - loss: 4.3107 - accuracy: 0.1505 - val_loss: 4.1481 - val_accuracy: 0.2120\n",
      "Epoch 39/500\n",
      "296/295 [==============================] - 72s 242ms/step - loss: 4.1797 - accuracy: 0.1570 - val_loss: 4.0529 - val_accuracy: 0.2272\n",
      "Epoch 40/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 4.0968 - accuracy: 0.1714 - val_loss: 3.9944 - val_accuracy: 0.2314\n",
      "Epoch 41/500\n",
      "296/295 [==============================] - 72s 244ms/step - loss: 3.9984 - accuracy: 0.1775 - val_loss: 3.9003 - val_accuracy: 0.2551\n",
      "Epoch 42/500\n",
      "296/295 [==============================] - 73s 245ms/step - loss: 3.9258 - accuracy: 0.1832 - val_loss: 3.8137 - val_accuracy: 0.2652\n",
      "Epoch 43/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 3.8297 - accuracy: 0.2020 - val_loss: 3.7470 - val_accuracy: 0.2703\n",
      "Epoch 44/500\n",
      "296/295 [==============================] - 72s 244ms/step - loss: 3.7576 - accuracy: 0.2035 - val_loss: 3.7019 - val_accuracy: 0.2863\n",
      "Epoch 45/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 3.7024 - accuracy: 0.2052 - val_loss: 3.6287 - val_accuracy: 0.2948\n",
      "Epoch 46/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 3.5932 - accuracy: 0.2172 - val_loss: 3.6005 - val_accuracy: 0.3057\n",
      "Epoch 47/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 3.5316 - accuracy: 0.2367 - val_loss: 3.4913 - val_accuracy: 0.3091\n",
      "Epoch 48/500\n",
      "296/295 [==============================] - 72s 245ms/step - loss: 3.4672 - accuracy: 0.2485 - val_loss: 3.4124 - val_accuracy: 0.3345\n",
      "Epoch 49/500\n",
      "296/295 [==============================] - 74s 248ms/step - loss: 3.3591 - accuracy: 0.2553 - val_loss: 3.3763 - val_accuracy: 0.3395\n",
      "Epoch 50/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 3.3158 - accuracy: 0.2718 - val_loss: 3.3509 - val_accuracy: 0.3387\n",
      "Epoch 51/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 3.2219 - accuracy: 0.2766 - val_loss: 3.2457 - val_accuracy: 0.3539\n",
      "Epoch 52/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 3.1703 - accuracy: 0.2828 - val_loss: 3.2561 - val_accuracy: 0.3463\n",
      "Epoch 53/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 3.1336 - accuracy: 0.2887 - val_loss: 3.1916 - val_accuracy: 0.3556\n",
      "Epoch 54/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 3.0092 - accuracy: 0.3039 - val_loss: 3.0879 - val_accuracy: 0.3742\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/295 [==============================] - 73s 247ms/step - loss: 2.9903 - accuracy: 0.3062 - val_loss: 3.0633 - val_accuracy: 0.3885\n",
      "Epoch 56/500\n",
      "296/295 [==============================] - 73s 245ms/step - loss: 2.9009 - accuracy: 0.3219 - val_loss: 3.0083 - val_accuracy: 0.3936\n",
      "Epoch 57/500\n",
      "296/295 [==============================] - 74s 250ms/step - loss: 2.8819 - accuracy: 0.3267 - val_loss: 2.9782 - val_accuracy: 0.3877\n",
      "Epoch 58/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 2.8076 - accuracy: 0.3375 - val_loss: 2.8944 - val_accuracy: 0.4155\n",
      "Epoch 59/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 2.7441 - accuracy: 0.3434 - val_loss: 2.8928 - val_accuracy: 0.4130\n",
      "Epoch 60/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 2.7112 - accuracy: 0.3487 - val_loss: 2.8263 - val_accuracy: 0.4231\n",
      "Epoch 61/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 2.6546 - accuracy: 0.3645 - val_loss: 2.8270 - val_accuracy: 0.4265\n",
      "Epoch 62/500\n",
      "296/295 [==============================] - 75s 252ms/step - loss: 2.6058 - accuracy: 0.3713 - val_loss: 2.8520 - val_accuracy: 0.4172\n",
      "Epoch 63/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 2.5311 - accuracy: 0.3950 - val_loss: 2.7294 - val_accuracy: 0.4451\n",
      "Epoch 64/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 2.4864 - accuracy: 0.3977 - val_loss: 2.6975 - val_accuracy: 0.4485\n",
      "Epoch 65/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 2.4251 - accuracy: 0.3988 - val_loss: 2.6862 - val_accuracy: 0.4578\n",
      "Epoch 66/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 2.4356 - accuracy: 0.4085 - val_loss: 2.6532 - val_accuracy: 0.4595\n",
      "Epoch 67/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 2.3398 - accuracy: 0.4210 - val_loss: 2.5863 - val_accuracy: 0.4578\n",
      "Epoch 68/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 2.3040 - accuracy: 0.4267 - val_loss: 2.6651 - val_accuracy: 0.4451\n",
      "Epoch 69/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 2.2633 - accuracy: 0.4480 - val_loss: 2.5601 - val_accuracy: 0.4747\n",
      "Epoch 70/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 2.1908 - accuracy: 0.4484 - val_loss: 2.5304 - val_accuracy: 0.4907\n",
      "Epoch 71/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 2.1888 - accuracy: 0.4501 - val_loss: 2.5069 - val_accuracy: 0.4865\n",
      "Epoch 72/500\n",
      "296/295 [==============================] - 75s 252ms/step - loss: 2.1531 - accuracy: 0.4596 - val_loss: 2.5036 - val_accuracy: 0.4865\n",
      "Epoch 73/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 2.1086 - accuracy: 0.4687 - val_loss: 2.4553 - val_accuracy: 0.5008\n",
      "Epoch 74/500\n",
      "296/295 [==============================] - 74s 250ms/step - loss: 2.0585 - accuracy: 0.4742 - val_loss: 2.4514 - val_accuracy: 0.4983\n",
      "Epoch 75/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 2.0220 - accuracy: 0.4886 - val_loss: 2.4207 - val_accuracy: 0.5059\n",
      "Epoch 76/500\n",
      "296/295 [==============================] - 74s 248ms/step - loss: 1.9925 - accuracy: 0.4814 - val_loss: 2.4386 - val_accuracy: 0.5017\n",
      "Epoch 77/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 1.9458 - accuracy: 0.5004 - val_loss: 2.3641 - val_accuracy: 0.5211\n",
      "Epoch 78/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 1.8874 - accuracy: 0.5137 - val_loss: 2.3696 - val_accuracy: 0.5203\n",
      "Epoch 79/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 1.8898 - accuracy: 0.5120 - val_loss: 2.3858 - val_accuracy: 0.5203\n",
      "Epoch 80/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 1.8648 - accuracy: 0.5144 - val_loss: 2.3051 - val_accuracy: 0.5312\n",
      "Epoch 81/500\n",
      "296/295 [==============================] - 74s 250ms/step - loss: 1.7884 - accuracy: 0.5372 - val_loss: 2.2923 - val_accuracy: 0.5439\n",
      "Epoch 82/500\n",
      "296/295 [==============================] - 78s 264ms/step - loss: 1.7819 - accuracy: 0.5389 - val_loss: 2.3019 - val_accuracy: 0.5321\n",
      "Epoch 83/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 1.7406 - accuracy: 0.5349 - val_loss: 2.2727 - val_accuracy: 0.5456\n",
      "Epoch 84/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 1.7580 - accuracy: 0.5444 - val_loss: 2.2345 - val_accuracy: 0.5625\n",
      "Epoch 85/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 1.6547 - accuracy: 0.5613 - val_loss: 2.2612 - val_accuracy: 0.5448\n",
      "Epoch 86/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 1.6494 - accuracy: 0.5623 - val_loss: 2.2043 - val_accuracy: 0.5642\n",
      "Epoch 87/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 1.6215 - accuracy: 0.5738 - val_loss: 2.2106 - val_accuracy: 0.5574\n",
      "Epoch 88/500\n",
      "296/295 [==============================] - 74s 250ms/step - loss: 1.6099 - accuracy: 0.5738 - val_loss: 2.1843 - val_accuracy: 0.5676\n",
      "Epoch 89/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 1.5528 - accuracy: 0.5807 - val_loss: 2.2061 - val_accuracy: 0.5583\n",
      "Epoch 90/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 1.5331 - accuracy: 0.5809 - val_loss: 2.1960 - val_accuracy: 0.5709\n",
      "Epoch 91/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 1.5202 - accuracy: 0.5949 - val_loss: 2.1421 - val_accuracy: 0.5769\n",
      "Epoch 92/500\n",
      "296/295 [==============================] - 75s 255ms/step - loss: 1.5100 - accuracy: 0.5936 - val_loss: 2.1327 - val_accuracy: 0.5752\n",
      "Epoch 93/500\n",
      "296/295 [==============================] - 77s 261ms/step - loss: 1.4627 - accuracy: 0.5989 - val_loss: 2.1452 - val_accuracy: 0.5701\n",
      "Epoch 94/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 1.4135 - accuracy: 0.6126 - val_loss: 2.1345 - val_accuracy: 0.5819\n",
      "Epoch 95/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 1.3655 - accuracy: 0.6192 - val_loss: 2.1236 - val_accuracy: 0.5870\n",
      "Epoch 96/500\n",
      "296/295 [==============================] - 82s 276ms/step - loss: 1.3532 - accuracy: 0.6240 - val_loss: 2.1133 - val_accuracy: 0.5836\n",
      "Epoch 97/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 1.3242 - accuracy: 0.6319 - val_loss: 2.0772 - val_accuracy: 0.5946\n",
      "Epoch 98/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 1.2995 - accuracy: 0.6422 - val_loss: 2.0813 - val_accuracy: 0.5997\n",
      "Epoch 99/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 1.2946 - accuracy: 0.6395 - val_loss: 2.0971 - val_accuracy: 0.5997\n",
      "Epoch 100/500\n",
      "296/295 [==============================] - 74s 248ms/step - loss: 1.2391 - accuracy: 0.6543 - val_loss: 2.0741 - val_accuracy: 0.6039\n",
      "Epoch 101/500\n",
      "296/295 [==============================] - 74s 251ms/step - loss: 1.2333 - accuracy: 0.6638 - val_loss: 2.1116 - val_accuracy: 0.6014\n",
      "Epoch 102/500\n",
      "296/295 [==============================] - 76s 255ms/step - loss: 1.2077 - accuracy: 0.6604 - val_loss: 2.0676 - val_accuracy: 0.6039\n",
      "Epoch 103/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 1.1633 - accuracy: 0.6743 - val_loss: 2.0503 - val_accuracy: 0.6064\n",
      "Epoch 104/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 1.2020 - accuracy: 0.6661 - val_loss: 2.0648 - val_accuracy: 0.6039\n",
      "Epoch 105/500\n",
      "296/295 [==============================] - 76s 255ms/step - loss: 1.1505 - accuracy: 0.6705 - val_loss: 2.0228 - val_accuracy: 0.6225\n",
      "Epoch 106/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 1.1201 - accuracy: 0.6849 - val_loss: 2.0474 - val_accuracy: 0.6106\n",
      "Epoch 107/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 1.1408 - accuracy: 0.6762 - val_loss: 2.0413 - val_accuracy: 0.6115\n",
      "Epoch 108/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 1.0828 - accuracy: 0.6993 - val_loss: 2.0112 - val_accuracy: 0.6166\n",
      "Epoch 109/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 1.0752 - accuracy: 0.6900 - val_loss: 2.0287 - val_accuracy: 0.6140\n",
      "Epoch 110/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 1.0600 - accuracy: 0.6910 - val_loss: 2.0027 - val_accuracy: 0.6267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 1.0195 - accuracy: 0.7120 - val_loss: 1.9905 - val_accuracy: 0.6216\n",
      "Epoch 112/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 1.0251 - accuracy: 0.7060 - val_loss: 1.9988 - val_accuracy: 0.6284\n",
      "Epoch 113/500\n",
      "296/295 [==============================] - 75s 255ms/step - loss: 0.9546 - accuracy: 0.7238 - val_loss: 2.0060 - val_accuracy: 0.6351\n",
      "Epoch 114/500\n",
      "296/295 [==============================] - 75s 255ms/step - loss: 0.9766 - accuracy: 0.7217 - val_loss: 1.9991 - val_accuracy: 0.6377\n",
      "Epoch 115/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.9708 - accuracy: 0.7219 - val_loss: 2.0343 - val_accuracy: 0.6250\n",
      "Epoch 116/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 0.9648 - accuracy: 0.7149 - val_loss: 1.9871 - val_accuracy: 0.6377\n",
      "Epoch 117/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 0.9139 - accuracy: 0.7361 - val_loss: 2.0134 - val_accuracy: 0.6419\n",
      "Epoch 118/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 0.9126 - accuracy: 0.7310 - val_loss: 2.0005 - val_accuracy: 0.6394\n",
      "Epoch 119/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 0.9292 - accuracy: 0.7291 - val_loss: 2.0050 - val_accuracy: 0.6334\n",
      "Epoch 120/500\n",
      "296/295 [==============================] - 74s 251ms/step - loss: 0.8874 - accuracy: 0.7403 - val_loss: 2.0007 - val_accuracy: 0.6402\n",
      "Epoch 121/500\n",
      "296/295 [==============================] - 74s 252ms/step - loss: 0.8731 - accuracy: 0.7479 - val_loss: 1.9697 - val_accuracy: 0.6495\n",
      "Epoch 122/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 0.8808 - accuracy: 0.7430 - val_loss: 1.9710 - val_accuracy: 0.6394\n",
      "Epoch 123/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 0.8473 - accuracy: 0.7578 - val_loss: 1.9710 - val_accuracy: 0.6571\n",
      "Epoch 124/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 0.7961 - accuracy: 0.7631 - val_loss: 1.9878 - val_accuracy: 0.6596\n",
      "Epoch 125/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.7913 - accuracy: 0.7637 - val_loss: 1.9959 - val_accuracy: 0.6461\n",
      "Epoch 126/500\n",
      "296/295 [==============================] - 75s 252ms/step - loss: 0.8241 - accuracy: 0.7568 - val_loss: 1.9867 - val_accuracy: 0.6503\n",
      "Epoch 127/500\n",
      "296/295 [==============================] - 74s 251ms/step - loss: 0.7823 - accuracy: 0.7648 - val_loss: 1.9600 - val_accuracy: 0.6639\n",
      "Epoch 128/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 0.7570 - accuracy: 0.7770 - val_loss: 1.9844 - val_accuracy: 0.6512\n",
      "Epoch 129/500\n",
      "296/295 [==============================] - 74s 250ms/step - loss: 0.7544 - accuracy: 0.7775 - val_loss: 1.9636 - val_accuracy: 0.6495\n",
      "Epoch 130/500\n",
      "296/295 [==============================] - 74s 248ms/step - loss: 0.7296 - accuracy: 0.7847 - val_loss: 1.9894 - val_accuracy: 0.6537\n",
      "Epoch 131/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.7373 - accuracy: 0.7840 - val_loss: 1.9563 - val_accuracy: 0.6588\n",
      "Epoch 132/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.7303 - accuracy: 0.7863 - val_loss: 1.9660 - val_accuracy: 0.6588\n",
      "Epoch 133/500\n",
      "296/295 [==============================] - 76s 256ms/step - loss: 0.7180 - accuracy: 0.7866 - val_loss: 1.9981 - val_accuracy: 0.6495\n",
      "Epoch 134/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.6950 - accuracy: 0.7978 - val_loss: 1.9564 - val_accuracy: 0.6647\n",
      "Epoch 135/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 0.6727 - accuracy: 0.7965 - val_loss: 1.9891 - val_accuracy: 0.6579\n",
      "Epoch 136/500\n",
      "296/295 [==============================] - 77s 261ms/step - loss: 0.6591 - accuracy: 0.8016 - val_loss: 1.9735 - val_accuracy: 0.6706\n",
      "Epoch 137/500\n",
      "296/295 [==============================] - 75s 252ms/step - loss: 0.6797 - accuracy: 0.7986 - val_loss: 1.9686 - val_accuracy: 0.6622\n",
      "Epoch 138/500\n",
      "296/295 [==============================] - 75s 255ms/step - loss: 0.6721 - accuracy: 0.8020 - val_loss: 2.0107 - val_accuracy: 0.6588\n",
      "Epoch 139/500\n",
      "296/295 [==============================] - 76s 255ms/step - loss: 0.5989 - accuracy: 0.8204 - val_loss: 1.9813 - val_accuracy: 0.6689\n",
      "Epoch 140/500\n",
      "296/295 [==============================] - 78s 262ms/step - loss: 0.6335 - accuracy: 0.8075 - val_loss: 2.0403 - val_accuracy: 0.6470\n",
      "Epoch 141/500\n",
      "296/295 [==============================] - 76s 256ms/step - loss: 0.5977 - accuracy: 0.8199 - val_loss: 2.0265 - val_accuracy: 0.6588\n",
      "Epoch 142/500\n",
      "296/295 [==============================] - 77s 260ms/step - loss: 0.6037 - accuracy: 0.8233 - val_loss: 1.9763 - val_accuracy: 0.6740\n",
      "Epoch 143/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 0.5980 - accuracy: 0.8111 - val_loss: 1.9578 - val_accuracy: 0.6765\n",
      "Epoch 144/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.5933 - accuracy: 0.8136 - val_loss: 1.9855 - val_accuracy: 0.6579\n",
      "Epoch 145/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 0.5884 - accuracy: 0.8252 - val_loss: 1.9814 - val_accuracy: 0.6681\n",
      "Epoch 146/500\n",
      "296/295 [==============================] - 79s 266ms/step - loss: 0.5668 - accuracy: 0.8292 - val_loss: 1.9394 - val_accuracy: 0.6757\n",
      "Epoch 147/500\n",
      "296/295 [==============================] - 81s 275ms/step - loss: 0.5690 - accuracy: 0.8259 - val_loss: 1.9981 - val_accuracy: 0.6647\n",
      "Epoch 148/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.5448 - accuracy: 0.8339 - val_loss: 1.9648 - val_accuracy: 0.6748\n",
      "Epoch 149/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.5555 - accuracy: 0.8299 - val_loss: 2.0074 - val_accuracy: 0.6706\n",
      "Epoch 150/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.5446 - accuracy: 0.8373 - val_loss: 1.9781 - val_accuracy: 0.6689\n",
      "Epoch 151/500\n",
      "296/295 [==============================] - 76s 256ms/step - loss: 0.5319 - accuracy: 0.8373 - val_loss: 1.9553 - val_accuracy: 0.6765\n",
      "Epoch 152/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.5230 - accuracy: 0.8390 - val_loss: 1.9888 - val_accuracy: 0.6740\n",
      "Epoch 153/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.5110 - accuracy: 0.8430 - val_loss: 2.0145 - val_accuracy: 0.6639\n",
      "Epoch 154/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.4825 - accuracy: 0.8529 - val_loss: 2.0501 - val_accuracy: 0.6799\n",
      "Epoch 155/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 0.5078 - accuracy: 0.8440 - val_loss: 1.9759 - val_accuracy: 0.6799\n",
      "Epoch 156/500\n",
      "296/295 [==============================] - 76s 256ms/step - loss: 0.5018 - accuracy: 0.8514 - val_loss: 2.0210 - val_accuracy: 0.6740\n",
      "Epoch 157/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 0.4829 - accuracy: 0.8516 - val_loss: 2.0265 - val_accuracy: 0.6748\n",
      "Epoch 158/500\n",
      "296/295 [==============================] - 76s 256ms/step - loss: 0.4913 - accuracy: 0.8468 - val_loss: 2.0178 - val_accuracy: 0.6782\n",
      "Epoch 159/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 0.4711 - accuracy: 0.8548 - val_loss: 1.9774 - val_accuracy: 0.6833\n",
      "Epoch 160/500\n",
      "296/295 [==============================] - 78s 263ms/step - loss: 0.4620 - accuracy: 0.8607 - val_loss: 2.0049 - val_accuracy: 0.6875\n",
      "Epoch 161/500\n",
      "296/295 [==============================] - 76s 256ms/step - loss: 0.4408 - accuracy: 0.8618 - val_loss: 2.0074 - val_accuracy: 0.6791\n",
      "Epoch 162/500\n",
      "296/295 [==============================] - 75s 255ms/step - loss: 0.4768 - accuracy: 0.8453 - val_loss: 1.9849 - val_accuracy: 0.6807\n",
      "Epoch 163/500\n",
      "296/295 [==============================] - 75s 255ms/step - loss: 0.4469 - accuracy: 0.8624 - val_loss: 1.9921 - val_accuracy: 0.6833\n",
      "Epoch 164/500\n",
      "296/295 [==============================] - 77s 262ms/step - loss: 0.4346 - accuracy: 0.8660 - val_loss: 2.0130 - val_accuracy: 0.6715\n",
      "Epoch 165/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.4202 - accuracy: 0.8692 - val_loss: 2.0019 - val_accuracy: 0.6816\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/295 [==============================] - 76s 258ms/step - loss: 0.4378 - accuracy: 0.8669 - val_loss: 2.0139 - val_accuracy: 0.6774\n",
      "Epoch 167/500\n",
      "296/295 [==============================] - 75s 255ms/step - loss: 0.3984 - accuracy: 0.8768 - val_loss: 2.0196 - val_accuracy: 0.6833\n",
      "Epoch 168/500\n",
      "296/295 [==============================] - 76s 256ms/step - loss: 0.4151 - accuracy: 0.8755 - val_loss: 1.9849 - val_accuracy: 0.6900\n",
      "Epoch 169/500\n",
      "296/295 [==============================] - 76s 255ms/step - loss: 0.4081 - accuracy: 0.8755 - val_loss: 2.0071 - val_accuracy: 0.6850\n",
      "Epoch 170/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.4214 - accuracy: 0.8726 - val_loss: 1.9768 - val_accuracy: 0.6926\n",
      "Epoch 171/500\n",
      "296/295 [==============================] - 75s 255ms/step - loss: 0.3949 - accuracy: 0.8728 - val_loss: 1.9790 - val_accuracy: 0.6867\n",
      "Epoch 172/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.3784 - accuracy: 0.8787 - val_loss: 1.9910 - val_accuracy: 0.6909\n",
      "Epoch 173/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.3994 - accuracy: 0.8787 - val_loss: 1.9479 - val_accuracy: 0.6883\n",
      "Epoch 174/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.3741 - accuracy: 0.8857 - val_loss: 2.0537 - val_accuracy: 0.6791\n",
      "Epoch 175/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.3747 - accuracy: 0.8802 - val_loss: 1.9925 - val_accuracy: 0.6867\n",
      "Epoch 176/500\n",
      "296/295 [==============================] - 77s 260ms/step - loss: 0.3714 - accuracy: 0.8869 - val_loss: 2.0307 - val_accuracy: 0.6816\n",
      "Epoch 177/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.3388 - accuracy: 0.8931 - val_loss: 2.0312 - val_accuracy: 0.6951\n",
      "Epoch 178/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.3674 - accuracy: 0.8888 - val_loss: 2.0219 - val_accuracy: 0.6824\n",
      "Epoch 179/500\n",
      "296/295 [==============================] - 76s 256ms/step - loss: 0.3580 - accuracy: 0.8886 - val_loss: 2.0229 - val_accuracy: 0.7019\n",
      "Epoch 180/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.3466 - accuracy: 0.8899 - val_loss: 2.0011 - val_accuracy: 0.6934\n",
      "Epoch 181/500\n",
      "296/295 [==============================] - 87s 294ms/step - loss: 0.3659 - accuracy: 0.8882 - val_loss: 2.0075 - val_accuracy: 0.6841\n",
      "Epoch 182/500\n",
      "296/295 [==============================] - 76s 256ms/step - loss: 0.3396 - accuracy: 0.8933 - val_loss: 2.0259 - val_accuracy: 0.6850\n",
      "Epoch 183/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.3265 - accuracy: 0.8937 - val_loss: 2.0542 - val_accuracy: 0.6917\n",
      "Epoch 184/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.3509 - accuracy: 0.8893 - val_loss: 2.0458 - val_accuracy: 0.6883\n",
      "Epoch 185/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 0.3365 - accuracy: 0.8945 - val_loss: 2.0679 - val_accuracy: 0.6892\n",
      "Epoch 186/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 0.3179 - accuracy: 0.9036 - val_loss: 2.0153 - val_accuracy: 0.6959\n",
      "Epoch 187/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.3082 - accuracy: 0.9013 - val_loss: 2.0404 - val_accuracy: 0.6976\n",
      "Epoch 188/500\n",
      "296/295 [==============================] - 77s 260ms/step - loss: 0.3104 - accuracy: 0.9024 - val_loss: 2.0414 - val_accuracy: 0.7044\n",
      "Epoch 189/500\n",
      "296/295 [==============================] - 79s 267ms/step - loss: 0.3326 - accuracy: 0.9007 - val_loss: 2.0913 - val_accuracy: 0.6858\n",
      "Epoch 190/500\n",
      "296/295 [==============================] - 76s 255ms/step - loss: 0.3201 - accuracy: 0.9019 - val_loss: 2.0073 - val_accuracy: 0.7019\n",
      "Epoch 191/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 0.3020 - accuracy: 0.9077 - val_loss: 2.0523 - val_accuracy: 0.6934\n",
      "Epoch 192/500\n",
      "296/295 [==============================] - 77s 260ms/step - loss: 0.2988 - accuracy: 0.9098 - val_loss: 2.0366 - val_accuracy: 0.6934\n",
      "Epoch 193/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 0.2995 - accuracy: 0.9096 - val_loss: 2.0412 - val_accuracy: 0.6934\n",
      "Epoch 194/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 0.2774 - accuracy: 0.9163 - val_loss: 2.0546 - val_accuracy: 0.7052\n",
      "Epoch 195/500\n",
      "296/295 [==============================] - 76s 256ms/step - loss: 0.2921 - accuracy: 0.9077 - val_loss: 2.0928 - val_accuracy: 0.6934\n",
      "Epoch 196/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.3061 - accuracy: 0.9041 - val_loss: 2.0897 - val_accuracy: 0.6875\n",
      "Epoch 197/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.3005 - accuracy: 0.9041 - val_loss: 2.0337 - val_accuracy: 0.6934\n",
      "Epoch 198/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.2890 - accuracy: 0.9150 - val_loss: 2.0191 - val_accuracy: 0.7019\n",
      "Epoch 199/500\n",
      "296/295 [==============================] - 78s 262ms/step - loss: 0.2820 - accuracy: 0.9098 - val_loss: 2.0493 - val_accuracy: 0.6951\n",
      "Epoch 200/500\n",
      "296/295 [==============================] - 78s 264ms/step - loss: 0.2399 - accuracy: 0.9246 - val_loss: 2.0513 - val_accuracy: 0.6959\n",
      "Epoch 201/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.2543 - accuracy: 0.9172 - val_loss: 2.1169 - val_accuracy: 0.6993\n",
      "Epoch 202/500\n",
      "296/295 [==============================] - 76s 256ms/step - loss: 0.2599 - accuracy: 0.9214 - val_loss: 2.1008 - val_accuracy: 0.6993\n",
      "Epoch 203/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 0.2767 - accuracy: 0.9117 - val_loss: 2.0967 - val_accuracy: 0.6951\n",
      "Epoch 204/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.2592 - accuracy: 0.9212 - val_loss: 2.1143 - val_accuracy: 0.6985\n",
      "Epoch 205/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.2504 - accuracy: 0.9220 - val_loss: 2.1619 - val_accuracy: 0.6934\n",
      "Epoch 206/500\n",
      "296/295 [==============================] - 75s 255ms/step - loss: 0.2595 - accuracy: 0.9180 - val_loss: 2.1208 - val_accuracy: 0.6934\n",
      "Epoch 207/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.2599 - accuracy: 0.9157 - val_loss: 2.1043 - val_accuracy: 0.6900\n",
      "Epoch 208/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.2339 - accuracy: 0.9254 - val_loss: 2.0486 - val_accuracy: 0.7086\n",
      "Epoch 209/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.2434 - accuracy: 0.9224 - val_loss: 2.0975 - val_accuracy: 0.7035\n",
      "Epoch 210/500\n",
      "296/295 [==============================] - 75s 254ms/step - loss: 0.2340 - accuracy: 0.9256 - val_loss: 2.1060 - val_accuracy: 0.6968\n",
      "Epoch 211/500\n",
      "296/295 [==============================] - 76s 256ms/step - loss: 0.2351 - accuracy: 0.9288 - val_loss: 2.0989 - val_accuracy: 0.6976\n",
      "Epoch 212/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.2328 - accuracy: 0.9292 - val_loss: 2.2117 - val_accuracy: 0.6757\n",
      "Epoch 213/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.2520 - accuracy: 0.9165 - val_loss: 2.0982 - val_accuracy: 0.6917\n",
      "Epoch 214/500\n",
      "296/295 [==============================] - 76s 255ms/step - loss: 0.2436 - accuracy: 0.9189 - val_loss: 2.2079 - val_accuracy: 0.6807\n",
      "Epoch 215/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.2217 - accuracy: 0.9284 - val_loss: 2.1267 - val_accuracy: 0.7111\n",
      "Epoch 216/500\n",
      "296/295 [==============================] - 75s 255ms/step - loss: 0.2322 - accuracy: 0.9275 - val_loss: 2.0952 - val_accuracy: 0.7095\n",
      "Epoch 217/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.2333 - accuracy: 0.9205 - val_loss: 2.0878 - val_accuracy: 0.7111\n",
      "Epoch 218/500\n",
      "296/295 [==============================] - 77s 260ms/step - loss: 0.2188 - accuracy: 0.9252 - val_loss: 2.1291 - val_accuracy: 0.7095\n",
      "Epoch 219/500\n",
      "296/295 [==============================] - 77s 261ms/step - loss: 0.2262 - accuracy: 0.9250 - val_loss: 2.1535 - val_accuracy: 0.7035\n",
      "Epoch 220/500\n",
      "296/295 [==============================] - 77s 261ms/step - loss: 0.2237 - accuracy: 0.9269 - val_loss: 2.1479 - val_accuracy: 0.7179\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/295 [==============================] - 77s 260ms/step - loss: 0.2128 - accuracy: 0.9332 - val_loss: 2.1438 - val_accuracy: 0.7019\n",
      "Epoch 222/500\n",
      "296/295 [==============================] - 75s 255ms/step - loss: 0.2119 - accuracy: 0.9334 - val_loss: 2.1409 - val_accuracy: 0.7052\n",
      "Epoch 223/500\n",
      "296/295 [==============================] - 76s 255ms/step - loss: 0.1936 - accuracy: 0.9408 - val_loss: 2.1613 - val_accuracy: 0.7019\n",
      "Epoch 224/500\n",
      "296/295 [==============================] - 75s 255ms/step - loss: 0.2162 - accuracy: 0.9301 - val_loss: 2.1736 - val_accuracy: 0.7052\n",
      "Epoch 225/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.2147 - accuracy: 0.9317 - val_loss: 2.1401 - val_accuracy: 0.6934\n",
      "Epoch 226/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.2090 - accuracy: 0.9301 - val_loss: 2.1392 - val_accuracy: 0.7086\n",
      "Epoch 227/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.2124 - accuracy: 0.9271 - val_loss: 2.1354 - val_accuracy: 0.7162\n",
      "Epoch 228/500\n",
      "296/295 [==============================] - 78s 264ms/step - loss: 0.2021 - accuracy: 0.9383 - val_loss: 2.1399 - val_accuracy: 0.7111\n",
      "Epoch 229/500\n",
      "296/295 [==============================] - 77s 261ms/step - loss: 0.1990 - accuracy: 0.9366 - val_loss: 2.1353 - val_accuracy: 0.7044\n",
      "Epoch 230/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.1966 - accuracy: 0.9413 - val_loss: 2.1421 - val_accuracy: 0.7120\n",
      "Epoch 231/500\n",
      "296/295 [==============================] - 77s 259ms/step - loss: 0.1977 - accuracy: 0.9387 - val_loss: 2.1549 - val_accuracy: 0.7128\n",
      "Epoch 232/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.1944 - accuracy: 0.9364 - val_loss: 2.1375 - val_accuracy: 0.7086\n",
      "Epoch 233/500\n",
      "296/295 [==============================] - 77s 261ms/step - loss: 0.1871 - accuracy: 0.9368 - val_loss: 2.1448 - val_accuracy: 0.7103\n",
      "Epoch 234/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.1792 - accuracy: 0.9446 - val_loss: 2.1523 - val_accuracy: 0.7188\n",
      "Epoch 235/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.1966 - accuracy: 0.9402 - val_loss: 2.1227 - val_accuracy: 0.7145\n",
      "Epoch 236/500\n",
      "296/295 [==============================] - 78s 264ms/step - loss: 0.1827 - accuracy: 0.9398 - val_loss: 2.1194 - val_accuracy: 0.7171\n",
      "Epoch 237/500\n",
      "296/295 [==============================] - 78s 262ms/step - loss: 0.2024 - accuracy: 0.9296 - val_loss: 2.1953 - val_accuracy: 0.7019\n",
      "Epoch 238/500\n",
      "296/295 [==============================] - 78s 263ms/step - loss: 0.1803 - accuracy: 0.9410 - val_loss: 2.1604 - val_accuracy: 0.7154\n",
      "Epoch 239/500\n",
      "296/295 [==============================] - 76s 256ms/step - loss: 0.1845 - accuracy: 0.9408 - val_loss: 2.1846 - val_accuracy: 0.7103\n",
      "Epoch 240/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.1787 - accuracy: 0.9432 - val_loss: 2.1583 - val_accuracy: 0.7086\n",
      "Epoch 241/500\n",
      "296/295 [==============================] - 77s 260ms/step - loss: 0.1730 - accuracy: 0.9434 - val_loss: 2.2048 - val_accuracy: 0.7128\n",
      "Epoch 242/500\n",
      "296/295 [==============================] - 76s 257ms/step - loss: 0.1853 - accuracy: 0.9413 - val_loss: 2.1212 - val_accuracy: 0.7188\n",
      "Epoch 243/500\n",
      "296/295 [==============================] - 72s 244ms/step - loss: 0.1695 - accuracy: 0.9465 - val_loss: 2.1726 - val_accuracy: 0.7204\n",
      "Epoch 244/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1765 - accuracy: 0.9453 - val_loss: 2.1181 - val_accuracy: 0.7188\n",
      "Epoch 245/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 0.1748 - accuracy: 0.9442 - val_loss: 2.2003 - val_accuracy: 0.7086\n",
      "Epoch 246/500\n",
      "296/295 [==============================] - 72s 245ms/step - loss: 0.1727 - accuracy: 0.9493 - val_loss: 2.1517 - val_accuracy: 0.7230\n",
      "Epoch 247/500\n",
      "296/295 [==============================] - 73s 245ms/step - loss: 0.1804 - accuracy: 0.9408 - val_loss: 2.2045 - val_accuracy: 0.7145\n",
      "Epoch 248/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 0.1891 - accuracy: 0.9419 - val_loss: 2.1748 - val_accuracy: 0.7120\n",
      "Epoch 249/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 0.1723 - accuracy: 0.9461 - val_loss: 2.2104 - val_accuracy: 0.7086\n",
      "Epoch 250/500\n",
      "296/295 [==============================] - 72s 244ms/step - loss: 0.1518 - accuracy: 0.9527 - val_loss: 2.2187 - val_accuracy: 0.7010\n",
      "Epoch 251/500\n",
      "296/295 [==============================] - 72s 244ms/step - loss: 0.1673 - accuracy: 0.9510 - val_loss: 2.2260 - val_accuracy: 0.7103\n",
      "Epoch 252/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 0.1698 - accuracy: 0.9427 - val_loss: 2.2150 - val_accuracy: 0.7086\n",
      "Epoch 253/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 0.1660 - accuracy: 0.9476 - val_loss: 2.2084 - val_accuracy: 0.7086\n",
      "Epoch 254/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1710 - accuracy: 0.9457 - val_loss: 2.1899 - val_accuracy: 0.7111\n",
      "Epoch 255/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1674 - accuracy: 0.9459 - val_loss: 2.1641 - val_accuracy: 0.7154\n",
      "Epoch 256/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 0.1493 - accuracy: 0.9569 - val_loss: 2.1771 - val_accuracy: 0.7204\n",
      "Epoch 257/500\n",
      "296/295 [==============================] - 74s 250ms/step - loss: 0.1569 - accuracy: 0.9516 - val_loss: 2.2333 - val_accuracy: 0.7061\n",
      "Epoch 258/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1584 - accuracy: 0.9463 - val_loss: 2.2123 - val_accuracy: 0.7128\n",
      "Epoch 259/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 0.1635 - accuracy: 0.9508 - val_loss: 2.1707 - val_accuracy: 0.7204\n",
      "Epoch 260/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 0.1532 - accuracy: 0.9510 - val_loss: 2.2233 - val_accuracy: 0.7221\n",
      "Epoch 261/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1369 - accuracy: 0.9560 - val_loss: 2.1905 - val_accuracy: 0.7204\n",
      "Epoch 262/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 0.1432 - accuracy: 0.9501 - val_loss: 2.2701 - val_accuracy: 0.7111\n",
      "Epoch 263/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1361 - accuracy: 0.9544 - val_loss: 2.2090 - val_accuracy: 0.7230\n",
      "Epoch 264/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 0.1408 - accuracy: 0.9508 - val_loss: 2.2425 - val_accuracy: 0.7120\n",
      "Epoch 265/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1483 - accuracy: 0.9503 - val_loss: 2.2382 - val_accuracy: 0.7230\n",
      "Epoch 266/500\n",
      "296/295 [==============================] - 74s 250ms/step - loss: 0.1385 - accuracy: 0.9573 - val_loss: 2.2560 - val_accuracy: 0.7078\n",
      "Epoch 267/500\n",
      "296/295 [==============================] - 78s 262ms/step - loss: 0.1426 - accuracy: 0.9554 - val_loss: 2.1938 - val_accuracy: 0.7120\n",
      "Epoch 268/500\n",
      "296/295 [==============================] - 75s 255ms/step - loss: 0.1369 - accuracy: 0.9560 - val_loss: 2.2225 - val_accuracy: 0.7171\n",
      "Epoch 269/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1520 - accuracy: 0.9556 - val_loss: 2.2075 - val_accuracy: 0.7086\n",
      "Epoch 270/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 0.1572 - accuracy: 0.9501 - val_loss: 2.1511 - val_accuracy: 0.7340\n",
      "Epoch 271/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1394 - accuracy: 0.9565 - val_loss: 2.2245 - val_accuracy: 0.7095\n",
      "Epoch 272/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 0.1335 - accuracy: 0.9607 - val_loss: 2.2163 - val_accuracy: 0.7204\n",
      "Epoch 273/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1270 - accuracy: 0.9598 - val_loss: 2.2342 - val_accuracy: 0.7213\n",
      "Epoch 274/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 0.1223 - accuracy: 0.9630 - val_loss: 2.2733 - val_accuracy: 0.7213\n",
      "Epoch 275/500\n",
      "296/295 [==============================] - 72s 245ms/step - loss: 0.1342 - accuracy: 0.9607 - val_loss: 2.2295 - val_accuracy: 0.7272\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/295 [==============================] - 73s 245ms/step - loss: 0.1193 - accuracy: 0.9641 - val_loss: 2.2749 - val_accuracy: 0.7188\n",
      "Epoch 277/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 0.1239 - accuracy: 0.9605 - val_loss: 2.2502 - val_accuracy: 0.7213\n",
      "Epoch 278/500\n",
      "296/295 [==============================] - 73s 245ms/step - loss: 0.1256 - accuracy: 0.9613 - val_loss: 2.2818 - val_accuracy: 0.7221\n",
      "Epoch 279/500\n",
      "296/295 [==============================] - 74s 250ms/step - loss: 0.1272 - accuracy: 0.9590 - val_loss: 2.2751 - val_accuracy: 0.7128\n",
      "Epoch 280/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1402 - accuracy: 0.9579 - val_loss: 2.2529 - val_accuracy: 0.7145\n",
      "Epoch 281/500\n",
      "296/295 [==============================] - 72s 245ms/step - loss: 0.1385 - accuracy: 0.9552 - val_loss: 2.2153 - val_accuracy: 0.7238\n",
      "Epoch 282/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 0.1385 - accuracy: 0.9529 - val_loss: 2.2426 - val_accuracy: 0.7145\n",
      "Epoch 283/500\n",
      "296/295 [==============================] - 74s 251ms/step - loss: 0.1389 - accuracy: 0.9531 - val_loss: 2.1976 - val_accuracy: 0.7196\n",
      "Epoch 284/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 0.1323 - accuracy: 0.9582 - val_loss: 2.2234 - val_accuracy: 0.7213\n",
      "Epoch 285/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 0.1213 - accuracy: 0.9601 - val_loss: 2.1974 - val_accuracy: 0.7204\n",
      "Epoch 286/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 0.1343 - accuracy: 0.9603 - val_loss: 2.2707 - val_accuracy: 0.7255\n",
      "Epoch 287/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 0.1259 - accuracy: 0.9573 - val_loss: 2.2214 - val_accuracy: 0.7255\n",
      "Epoch 288/500\n",
      "296/295 [==============================] - 73s 245ms/step - loss: 0.1232 - accuracy: 0.9613 - val_loss: 2.2629 - val_accuracy: 0.7145\n",
      "Epoch 289/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 0.1218 - accuracy: 0.9569 - val_loss: 2.3429 - val_accuracy: 0.7171\n",
      "Epoch 290/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1164 - accuracy: 0.9628 - val_loss: 2.2492 - val_accuracy: 0.7162\n",
      "Epoch 291/500\n",
      "296/295 [==============================] - 74s 250ms/step - loss: 0.1311 - accuracy: 0.9590 - val_loss: 2.2491 - val_accuracy: 0.7204\n",
      "Epoch 292/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 0.1132 - accuracy: 0.9672 - val_loss: 2.2353 - val_accuracy: 0.7078\n",
      "Epoch 293/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.1171 - accuracy: 0.9639 - val_loss: 2.2852 - val_accuracy: 0.7179\n",
      "Epoch 294/500\n",
      "296/295 [==============================] - 80s 271ms/step - loss: 0.1179 - accuracy: 0.9630 - val_loss: 2.2811 - val_accuracy: 0.7128\n",
      "Epoch 295/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 0.0959 - accuracy: 0.9696 - val_loss: 2.3299 - val_accuracy: 0.7086\n",
      "Epoch 296/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 0.1258 - accuracy: 0.9601 - val_loss: 2.2930 - val_accuracy: 0.7204\n",
      "Epoch 297/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1035 - accuracy: 0.9658 - val_loss: 2.2790 - val_accuracy: 0.7323\n",
      "Epoch 298/500\n",
      "296/295 [==============================] - 72s 245ms/step - loss: 0.1220 - accuracy: 0.9611 - val_loss: 2.2714 - val_accuracy: 0.7238\n",
      "Epoch 299/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 0.1270 - accuracy: 0.9594 - val_loss: 2.3009 - val_accuracy: 0.7204\n",
      "Epoch 300/500\n",
      "296/295 [==============================] - 73s 245ms/step - loss: 0.1326 - accuracy: 0.9579 - val_loss: 2.2296 - val_accuracy: 0.7289\n",
      "Epoch 301/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 0.1060 - accuracy: 0.9675 - val_loss: 2.2551 - val_accuracy: 0.7196\n",
      "Epoch 302/500\n",
      "296/295 [==============================] - 82s 278ms/step - loss: 0.1175 - accuracy: 0.9634 - val_loss: 2.2544 - val_accuracy: 0.7280\n",
      "Epoch 303/500\n",
      "296/295 [==============================] - 75s 252ms/step - loss: 0.1140 - accuracy: 0.9664 - val_loss: 2.2875 - val_accuracy: 0.7179\n",
      "Epoch 304/500\n",
      "296/295 [==============================] - 74s 249ms/step - loss: 0.1203 - accuracy: 0.9613 - val_loss: 2.2209 - val_accuracy: 0.7331\n",
      "Epoch 305/500\n",
      "296/295 [==============================] - 74s 251ms/step - loss: 0.0967 - accuracy: 0.9672 - val_loss: 2.2369 - val_accuracy: 0.7340\n",
      "Epoch 306/500\n",
      "296/295 [==============================] - 75s 253ms/step - loss: 0.1139 - accuracy: 0.9649 - val_loss: 2.2845 - val_accuracy: 0.7230\n",
      "Epoch 307/500\n",
      "296/295 [==============================] - 73s 245ms/step - loss: 0.1055 - accuracy: 0.9656 - val_loss: 2.3199 - val_accuracy: 0.7213\n",
      "Epoch 308/500\n",
      "296/295 [==============================] - 74s 251ms/step - loss: 0.1113 - accuracy: 0.9670 - val_loss: 2.3386 - val_accuracy: 0.7272\n",
      "Epoch 309/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1139 - accuracy: 0.9626 - val_loss: 2.2276 - val_accuracy: 0.7340\n",
      "Epoch 310/500\n",
      "296/295 [==============================] - 73s 247ms/step - loss: 0.1172 - accuracy: 0.9609 - val_loss: 2.2077 - val_accuracy: 0.7297\n",
      "Epoch 311/500\n",
      "296/295 [==============================] - 70s 238ms/step - loss: 0.1009 - accuracy: 0.9672 - val_loss: 2.3176 - val_accuracy: 0.7297\n",
      "Epoch 312/500\n",
      "296/295 [==============================] - 71s 240ms/step - loss: 0.0866 - accuracy: 0.9717 - val_loss: 2.2810 - val_accuracy: 0.7221\n",
      "Epoch 313/500\n",
      "296/295 [==============================] - 70s 237ms/step - loss: 0.1008 - accuracy: 0.9694 - val_loss: 2.2541 - val_accuracy: 0.7323\n",
      "Epoch 314/500\n",
      "296/295 [==============================] - 70s 238ms/step - loss: 0.0966 - accuracy: 0.9685 - val_loss: 2.2686 - val_accuracy: 0.7272\n",
      "Epoch 315/500\n",
      "296/295 [==============================] - 71s 239ms/step - loss: 0.0972 - accuracy: 0.9687 - val_loss: 2.2688 - val_accuracy: 0.7289\n",
      "Epoch 316/500\n",
      "296/295 [==============================] - 73s 245ms/step - loss: 0.1045 - accuracy: 0.9675 - val_loss: 2.2774 - val_accuracy: 0.7314\n",
      "Epoch 317/500\n",
      "296/295 [==============================] - 72s 242ms/step - loss: 0.1092 - accuracy: 0.9672 - val_loss: 2.2720 - val_accuracy: 0.7306\n",
      "Epoch 318/500\n",
      "296/295 [==============================] - 71s 240ms/step - loss: 0.1075 - accuracy: 0.9647 - val_loss: 2.2552 - val_accuracy: 0.7348\n",
      "Epoch 319/500\n",
      "296/295 [==============================] - 71s 240ms/step - loss: 0.1010 - accuracy: 0.9668 - val_loss: 2.2796 - val_accuracy: 0.7306\n",
      "Epoch 320/500\n",
      "296/295 [==============================] - 71s 239ms/step - loss: 0.1102 - accuracy: 0.9675 - val_loss: 2.2498 - val_accuracy: 0.7306\n",
      "Epoch 321/500\n",
      "296/295 [==============================] - 72s 243ms/step - loss: 0.1114 - accuracy: 0.9649 - val_loss: 2.2482 - val_accuracy: 0.7196\n",
      "Epoch 322/500\n",
      "296/295 [==============================] - 71s 239ms/step - loss: 0.1032 - accuracy: 0.9662 - val_loss: 2.3466 - val_accuracy: 0.7171\n",
      "Epoch 323/500\n",
      "296/295 [==============================] - 72s 244ms/step - loss: 0.0963 - accuracy: 0.9715 - val_loss: 2.2433 - val_accuracy: 0.7323\n",
      "Epoch 324/500\n",
      "296/295 [==============================] - 71s 241ms/step - loss: 0.1068 - accuracy: 0.9660 - val_loss: 2.2575 - val_accuracy: 0.7264\n",
      "Epoch 325/500\n",
      "296/295 [==============================] - 73s 248ms/step - loss: 0.0995 - accuracy: 0.9696 - val_loss: 2.2362 - val_accuracy: 0.7213\n",
      "Epoch 326/500\n",
      "296/295 [==============================] - 72s 244ms/step - loss: 0.0924 - accuracy: 0.9700 - val_loss: 2.2488 - val_accuracy: 0.7272\n",
      "Epoch 327/500\n",
      "296/295 [==============================] - 72s 242ms/step - loss: 0.0761 - accuracy: 0.9759 - val_loss: 2.2791 - val_accuracy: 0.7306\n",
      "Epoch 328/500\n",
      "296/295 [==============================] - 71s 241ms/step - loss: 0.0997 - accuracy: 0.9677 - val_loss: 2.2814 - val_accuracy: 0.7238\n",
      "Epoch 329/500\n",
      "296/295 [==============================] - 77s 261ms/step - loss: 0.0939 - accuracy: 0.9694 - val_loss: 2.2640 - val_accuracy: 0.7348\n",
      "Epoch 330/500\n",
      "296/295 [==============================] - 71s 239ms/step - loss: 0.0915 - accuracy: 0.9734 - val_loss: 2.2418 - val_accuracy: 0.7340\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/295 [==============================] - 70s 238ms/step - loss: 0.0899 - accuracy: 0.9721 - val_loss: 2.2794 - val_accuracy: 0.7297\n",
      "Epoch 332/500\n",
      "296/295 [==============================] - 70s 237ms/step - loss: 0.0899 - accuracy: 0.9710 - val_loss: 2.3135 - val_accuracy: 0.7416\n",
      "Epoch 333/500\n",
      "296/295 [==============================] - 73s 245ms/step - loss: 0.0948 - accuracy: 0.9696 - val_loss: 2.2994 - val_accuracy: 0.7323\n",
      "Epoch 334/500\n",
      "296/295 [==============================] - 76s 258ms/step - loss: 0.1005 - accuracy: 0.9647 - val_loss: 2.2938 - val_accuracy: 0.7340\n",
      "Epoch 335/500\n",
      "296/295 [==============================] - 73s 246ms/step - loss: 0.0896 - accuracy: 0.9706 - val_loss: 2.2957 - val_accuracy: 0.7306\n",
      "Epoch 336/500\n",
      "292/295 [============================>.] - ETA: 0s - loss: 0.0840 - accuracy: 0.9705"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6eab8de9bda3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m history = model.fit_generator(img_gen.flow(train_images*255, train_labels, batch_size = 16),\n\u001b[1;32m----> 4\u001b[1;33m                                       steps_per_epoch = len(train_images)/16, validation_data = (test_images,test_labels), epochs = 500)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1479\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \"\"\"\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    517\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \"\"\"\n\u001b[0;32m    960\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit_generator(img_gen.flow(train_images*255, train_labels, batch_size = 16),\n",
    "                                      steps_per_epoch = len(train_images)/16, validation_data = (test_images,test_labels), epochs = 500)\n",
    "\n",
    "\n",
    "# history = model.fit(train_images*255, train_labels, batch_size=16, validation_split=0.2, epochs=500, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('./model in 33. after small dataset') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Accuracy: {:.2f} %, Val Accuracy {:.2f} %'.format(100*history.history['accuracy'][-1],\n",
    "#                                                          100*history.history['val_accuracy'][-1]))\n",
    "# print('Loss: {:.4f} , Val Loss {:.4f}'.format(history.history['loss'][-1], history.history['val_loss'][-1]))\n",
    "# print('Precision: {:.4f} , Val Precision {:.4f}'.format(history.history['precision'][-1], history.history['val_precision'][-1]))\n",
    "# print('Recall: {:.4f}, Val Recall {:.4f}'.format(history.history['recall'][-1], history.history['val_recall'][-1]))\n",
    "# print('AUC: {:.4f}, Val AUC {:.4f}'.format(history.history['auc'][-1], history.history['val_auc'][-1]))\n",
    "# print()\n",
    "# print('TP: {:.0f}'.format(history.history['tp'][-1]))\n",
    "# print('FP: {:.0f}'.format(history.history['fp'][-1]))\n",
    "# print('TN: {:.0f}'.format(history.history['tn'][-1]))\n",
    "# print('FN: {:.0f}'.format(history.history['fn'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot  # plot 可以視為畫布\n",
    "import math\n",
    "\n",
    "def show_feature_label_prediction(features, labels, predictions, indexList):\n",
    "    num = len(indexList)\n",
    "\n",
    "    plot.gcf().set_size_inches( 2*5, (2+0.4)*math.ceil(num/5) )\n",
    "\n",
    "    loc = 0\n",
    "    for i in indexList :\n",
    "        loc += 1\n",
    "        subp = plot.subplot( math.ceil(num/5), 5, loc )\n",
    "        subp.imshow( features[i], cmap='binary' )\n",
    "\n",
    "        if( len(predictions) > 0 ) :\n",
    "            title = 'prediction = ' + str(predictions[i])\n",
    "            title += (' (o)' if predictions[i]==labels[i] else ' (x)') # predict result\n",
    "            title += '\\nlabel = ' + str(labels[i])\n",
    "        else :\n",
    "            title = 'label = ' + str(labels[i])\n",
    "\n",
    "        subp.set_title( title, fontsize=12 )\n",
    "        subp.set_xticks( [] )\n",
    "        subp.set_yticks( [] )\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_misprediction(features, labels, predictions, indexList):\n",
    "    num = len(indexList)\n",
    "\n",
    "    plot.gcf().set_size_inches( 2*5, (2+0.4)*math.ceil(num/5) )\n",
    "\n",
    "    loc = 0\n",
    "    for i in indexList :\n",
    "\n",
    "        if(len(predictions)> 0) & (predictions[i]!=labels[i]):\n",
    "            loc += 1\n",
    "            subp = plot.subplot( math.ceil(num/5), 5, loc )\n",
    "            subp.imshow(features[i], cmap='binary' )\n",
    "            title = str(labels[i])\n",
    "            title += (' (o)' if predictions[i]==labels[i] else ' (x)') # predict result\n",
    "            subp.set_title( title, fontsize=12 )\n",
    "        else :\n",
    "            continue\n",
    "#             title = 'label = ' + str(labels[i])\n",
    "\n",
    "        \n",
    "        subp.set_xticks( [] )\n",
    "        subp.set_yticks( [] )\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = []\n",
    "prediction = model.predict_classes(test_images)\n",
    "for i in range(len(test_labels_org)):\n",
    "    if prediction[i]!=test_labels_org[i]:\n",
    "        re.append(test_labels_org[i])\n",
    "# sorted(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(test_images)\n",
    "show_feature_label_prediction(test_images, test_labels_org, prediction, range(0, len(test_labels_org)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(test_images)\n",
    "show_misprediction(test_images, test_labels_org, prediction, range(0, len(test_labels_org)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'name': np.unique(list(name_list))})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
